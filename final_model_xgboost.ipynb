{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9g9jqfsw4d7d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.core.fromnumeric import _all_dispatcher\n",
    "import pandas as pd\n",
    "import joblib\n",
    "np.random.seed(2021)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKEGy-Od6uyX"
   },
   "source": [
    "# df --> whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m9AAIOQa6PsH"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_modified.gz\", compression='gzip', header='infer')\n",
    "Y = df['click']\n",
    "# discard some columns\n",
    "# unused_cols = [\"id\", 'site_id', 'app_id']\n",
    "# df.drop(unused_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "Q3ND2A-a6iSW",
    "outputId": "86fb86c0-598f-4650-abd1-1a70cf4868d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>device_id</th>\n",
       "      <th>device_ip</th>\n",
       "      <th>device_model</th>\n",
       "      <th>...</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>device_ip_count</th>\n",
       "      <th>device_id_count</th>\n",
       "      <th>hour_count</th>\n",
       "      <th>user</th>\n",
       "      <th>hourly_user_count</th>\n",
       "      <th>click_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>078d3465</td>\n",
       "      <td>dd641cc7</td>\n",
       "      <td>8fd0aea4</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>ddd2926e</td>\n",
       "      <td>44956a24</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>7647</td>\n",
       "      <td>2533255</td>\n",
       "      <td>140117</td>\n",
       "      <td>ddd2926e44956a24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>first string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>078d3465</td>\n",
       "      <td>dd641cc7</td>\n",
       "      <td>8fd0aea4</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>96809ac8</td>\n",
       "      <td>711ee120</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2533255</td>\n",
       "      <td>140117</td>\n",
       "      <td>96809ac8711ee120</td>\n",
       "      <td>3.0</td>\n",
       "      <td>first string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>078d3465</td>\n",
       "      <td>dd641cc7</td>\n",
       "      <td>8fd0aea4</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>b3cf8def</td>\n",
       "      <td>8a4875bd</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2533255</td>\n",
       "      <td>140117</td>\n",
       "      <td>b3cf8def8a4875bd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>first string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>078d3465</td>\n",
       "      <td>dd641cc7</td>\n",
       "      <td>8fd0aea4</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>e8275b8f</td>\n",
       "      <td>6332421a</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2533255</td>\n",
       "      <td>140117</td>\n",
       "      <td>e8275b8f6332421a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>first string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>a2af7bee</td>\n",
       "      <td>cbee4b41</td>\n",
       "      <td>72722551</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>9644d0bf</td>\n",
       "      <td>779d90c2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2533255</td>\n",
       "      <td>140117</td>\n",
       "      <td>9644d0bf779d90c2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>first string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683782</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>c12ebe86</td>\n",
       "      <td>c1aa3c04</td>\n",
       "      <td>74073276</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>8546df25</td>\n",
       "      <td>67fb3069</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "      <td>2533255</td>\n",
       "      <td>147294</td>\n",
       "      <td>8546df2567fb3069</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683783</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>c12ebe86</td>\n",
       "      <td>c1aa3c04</td>\n",
       "      <td>74073276</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>98e4ada3</td>\n",
       "      <td>b314d7b9</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>-1</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2533255</td>\n",
       "      <td>147294</td>\n",
       "      <td>98e4ada3b314d7b9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683784</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5bb07e04</td>\n",
       "      <td>b256a9bc</td>\n",
       "      <td>f66779e6</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>76dc4769</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>378614</td>\n",
       "      <td>2533255</td>\n",
       "      <td>147294</td>\n",
       "      <td>dc38aa0776dc4769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>first string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683785</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>c12ebe86</td>\n",
       "      <td>c1aa3c04</td>\n",
       "      <td>74073276</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>e5693fd8</td>\n",
       "      <td>7120e05e</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2533255</td>\n",
       "      <td>147294</td>\n",
       "      <td>e5693fd87120e05e</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683786</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>c12ebe86</td>\n",
       "      <td>c1aa3c04</td>\n",
       "      <td>74073276</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>af4a9787</td>\n",
       "      <td>0b188ab3</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>593</td>\n",
       "      <td>2533255</td>\n",
       "      <td>147294</td>\n",
       "      <td>af4a97870b188ab3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0000010001000000001000100000000000010000000100...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2683787 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         click  hour  C1  banner_pos   site_id site_domain site_category  \\\n",
       "0            0     0   5           0  078d3465    dd641cc7      8fd0aea4   \n",
       "1            0     0   5           0  078d3465    dd641cc7      8fd0aea4   \n",
       "2            0     0   5           0  078d3465    dd641cc7      8fd0aea4   \n",
       "3            0     0   5           0  078d3465    dd641cc7      8fd0aea4   \n",
       "4            0     0   5           1  a2af7bee    cbee4b41      72722551   \n",
       "...        ...   ...  ..         ...       ...         ...           ...   \n",
       "2683782      0     1   5           1  c12ebe86    c1aa3c04      74073276   \n",
       "2683783      0     1   5           1  c12ebe86    c1aa3c04      74073276   \n",
       "2683784      1     1   5           0  5bb07e04    b256a9bc      f66779e6   \n",
       "2683785      0     1   5           1  c12ebe86    c1aa3c04      74073276   \n",
       "2683786      0     1   5           1  c12ebe86    c1aa3c04      74073276   \n",
       "\n",
       "        device_id device_ip device_model  ...  C19  C20  C21  day_of_week  \\\n",
       "0        a99f214a  ddd2926e     44956a24  ...    3   -1   67            1   \n",
       "1        a99f214a  96809ac8     711ee120  ...    3   85   67            1   \n",
       "2        a99f214a  b3cf8def     8a4875bd  ...    3   85   67            1   \n",
       "3        a99f214a  e8275b8f     6332421a  ...    3   85   67            1   \n",
       "4        a99f214a  9644d0bf     779d90c2  ...    3   -1  145            1   \n",
       "...           ...       ...          ...  ...  ...  ...  ...          ...   \n",
       "2683782  a99f214a  8546df25     67fb3069  ...    7   -1  145            2   \n",
       "2683783  a99f214a  98e4ada3     b314d7b9  ...  131   -1   49            2   \n",
       "2683784  a99f214a   Unknown     76dc4769  ...  135   -1   11            2   \n",
       "2683785  a99f214a  e5693fd8     7120e05e  ...    7   -1   11            2   \n",
       "2683786  a99f214a  af4a9787     0b188ab3  ...    7   -1   11            2   \n",
       "\n",
       "         device_ip_count  device_id_count  hour_count              user  \\\n",
       "0                   7647          2533255      140117  ddd2926e44956a24   \n",
       "1                      7          2533255      140117  96809ac8711ee120   \n",
       "2                      2          2533255      140117  b3cf8def8a4875bd   \n",
       "3                      6          2533255      140117  e8275b8f6332421a   \n",
       "4                     31          2533255      140117  9644d0bf779d90c2   \n",
       "...                  ...              ...         ...               ...   \n",
       "2683782              229          2533255      147294  8546df2567fb3069   \n",
       "2683783               18          2533255      147294  98e4ada3b314d7b9   \n",
       "2683784           378614          2533255      147294  dc38aa0776dc4769   \n",
       "2683785                9          2533255      147294  e5693fd87120e05e   \n",
       "2683786              593          2533255      147294  af4a97870b188ab3   \n",
       "\n",
       "         hourly_user_count                                      click_history  \n",
       "0                      4.0                                       first string  \n",
       "1                      3.0                                       first string  \n",
       "2                      2.0                                       first string  \n",
       "3                      2.0                                       first string  \n",
       "4                     15.0                                       first string  \n",
       "...                    ...                                                ...  \n",
       "2683782                5.0                                               1110  \n",
       "2683783                4.0                                                010  \n",
       "2683784                1.0                                       first string  \n",
       "2683785                4.0                                            0000010  \n",
       "2683786               27.0  0000010001000000001000100000000000010000000100...  \n",
       "\n",
       "[2683787 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h07Rn7BO65SV"
   },
   "source": [
    "### df_train --> our own training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "KzQV-h336kdB",
    "outputId": "a7199812-80e7-443f-8966-a1d091c044c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2051084 entries, 0 to 2051083\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   click              int64 \n",
      " 1   hour               int64 \n",
      " 2   C1                 int64 \n",
      " 3   banner_pos         int64 \n",
      " 4   site_id            object\n",
      " 5   site_domain        object\n",
      " 6   site_category      object\n",
      " 7   device_id          object\n",
      " 8   device_ip          object\n",
      " 9   device_model       object\n",
      " 10  device_type        int64 \n",
      " 11  device_conn_type   int64 \n",
      " 12  C14                int64 \n",
      " 13  C15                int64 \n",
      " 14  C16                int64 \n",
      " 15  C17                int64 \n",
      " 16  C18                int64 \n",
      " 17  C19                int64 \n",
      " 18  C20                int64 \n",
      " 19  C21                int64 \n",
      " 20  day_of_week        int64 \n",
      " 21  device_ip_count    int64 \n",
      " 22  device_id_count    int64 \n",
      " 23  hour_count         int64 \n",
      " 24  user               object\n",
      " 25  hourly_user_count  int64 \n",
      " 26  click_history      object\n",
      "dtypes: int64(19), object(8)\n",
      "memory usage: 422.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train_df.gz\", compression='gzip', header='infer')\n",
    "Y_train = df_train['click']\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jeoo829H8jBD",
    "outputId": "d4cf107c-8ea9-4322-c9cc-58ab76c19eef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: click, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnP76fBc7XnH"
   },
   "source": [
    "### Optimal catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "86oGBfTW79e9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_cat = df_train.copy()\n",
    "unused_cols = ['click']\n",
    "df_cat.drop(unused_cols, axis=1, inplace=True)\n",
    "cut_off = int(len(df_cat) * 0.7)\n",
    "X_train_cat = df_cat.iloc[:cut_off, :]\n",
    "X_test_cat = df_cat.iloc[cut_off:, :]\n",
    "y_train_cat = Y_train[:cut_off]\n",
    "y_test_cat = Y_train[cut_off:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GUxTzni7GeM"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "categorical_f = ['C1', 'banner_pos','site_id', 'site_domain','site_category','device_id','device_ip','device_model',\n",
    "                 'device_type','device_conn_type', 'C14','C15','C16','C17','C18', 'C19','C20','C21',\n",
    "                 'day_of_week', 'user', 'click_history']\n",
    "\n",
    "cat1 = CatBoostClassifier(iterations=20,learning_rate=0.1,depth=7,loss_function='Logloss', \n",
    "                          cat_features=categorical_f,verbose=False)\n",
    "\n",
    "param = {\n",
    "    'iterations': Integer(10, 300),\n",
    "    'depth': Integer(1, 8),\n",
    "    'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "    'random_strength': Real(1e-9, 10, 'log-uniform'),\n",
    "    'bagging_temperature': Real(0.0, 1.0),\n",
    "    'border_count': Integer(1, 255),\n",
    "    'l2_leaf_reg': Integer(2, 30),\n",
    "    'scale_pos_weight':Real(0.01, 1.0, 'uniform')\n",
    "}\n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_c = BayesSearchCV(\n",
    "    cat1,\n",
    "    param,\n",
    "    scoring = LogLoss,\n",
    "    n_iter=64,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# executes bayesian optimization\n",
    "opt_c.fit(X_train_cat, y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2YJ57FXAAUG"
   },
   "outputs": [],
   "source": [
    "opt_c.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DJ-5l6SXIUW"
   },
   "outputs": [],
   "source": [
    "opt_c.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_tFvXZ-XnMY"
   },
   "source": [
    "### optimal xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "NGIQZlbCAvYW"
   },
   "outputs": [],
   "source": [
    "df_xgb = df_train.copy()\n",
    "\n",
    "def convert_obj_to_int(self):\n",
    "    \n",
    "    object_list_columns = self.columns\n",
    "    object_list_dtypes = self.dtypes\n",
    "    new_col_suffix = '_int'\n",
    "    for index in range(0,len(object_list_columns)):\n",
    "        if object_list_dtypes[index] == object :\n",
    "            self[object_list_columns[index]+new_col_suffix] = self[object_list_columns[index]].map( lambda  x: hash(x))\n",
    "            self.drop([object_list_columns[index]],inplace=True,axis=1)\n",
    "    return self\n",
    "\n",
    "df_xgb = convert_obj_to_int(df_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "xES1E4ObF3Wj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:20:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:20:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:21:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:21:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:22:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:22:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:23:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:23:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:24:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:24:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:25:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:25:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:26:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:26:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:26:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:26:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:27:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:27:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:28:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:28:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:28:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:29:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:29:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:29:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:30:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:30:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:31:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:31:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:32:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:32:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:33:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:33:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:34:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:36:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:36:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:37:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:37:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:38:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:38:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:39:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:40:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:40:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:41:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:41:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:42:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:42:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:43:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:43:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:44:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:44:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:45:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:45:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:48:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:48:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:49:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:50:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:52:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:52:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:53:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:53:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:54:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:54:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:56:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:56:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:57:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:57:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:58:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:58:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:59:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:59:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:00:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:00:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:01:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:01:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:02:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:02:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:03:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:03:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:03:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:03:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:04:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:04:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:04:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:04:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:05:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:05:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:06:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:06:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:07:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:07:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:08:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:09:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:09:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:10:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:10:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:10:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:10:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:11:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:11:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:12:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:12:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:13:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:13:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:14:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:15:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:15:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:16:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:16:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:17:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:17:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:18:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:18:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:19:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:19:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:20:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:20:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:22:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:22:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:23:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:23:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:24:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:24:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:25:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:25:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:27:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:27:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:28:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:28:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:29:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:29:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:30:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:30:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:32:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:32:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:34:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:34:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:37:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:40:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:43:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:43:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:45:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:45:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:46:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:46:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:47:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:47:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:48:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:48:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:49:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:49:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:50:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:50:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:51:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:51:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:52:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:52:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:53:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:53:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:54:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:54:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:55:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:55:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:55:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:55:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:56:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:56:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:56:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:57:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:57:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:57:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:58:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:58:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:59:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:00:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:01:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:01:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:02:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:02:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:03:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:04:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:05:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:05:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:06:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:06:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:07:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:07:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:09:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:09:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:10:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:10:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:11:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:11:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:11:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:11:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:12:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:12:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:13:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:13:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:14:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:14:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:16:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:16:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:17:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:19:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:19:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:21:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:21:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:23:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:23:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:25:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:25:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:26:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:26:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:28:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:28:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:30:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:30:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:31:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:31:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:33:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:33:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:34:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:34:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:35:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:36:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:36:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:37:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:37:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:39:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:39:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:42:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:42:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:43:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:43:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:45:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:45:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:45:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:45:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:46:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:46:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:47:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:47:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:48:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:49:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:49:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:50:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:50:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:51:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:52:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:52:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:53:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:53:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:54:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:55:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:56:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:56:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:56:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:57:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:57:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:58:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:59:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:00:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:00:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:00:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:01:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:02:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:02:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:02:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:03:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:03:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:03:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:05:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:06:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:08:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:08:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:09:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:11:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:11:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:13:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:13:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:13:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:14:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:15:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:17:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:19:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:19:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:20:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:20:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:22:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:25:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:27:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:30:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:32:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:32:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:35:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:36:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:36:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:37:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:38:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:38:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:39:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:39:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:40:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:41:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:41:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:42:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:42:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:44:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:44:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:45:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:46:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:47:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:49:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:49:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:50:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:52:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:53:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:57:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:58:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:59:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:59:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:00:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:00:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:00:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:02:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:03:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:05:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:05:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:06:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:06:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:08:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBClassifier(alpha=0, base_score=None, booster=None,\n",
       "                                      colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=0.5, gamma=0,\n",
       "                                      gpu_id=None, importance_type='gain',\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=0.1, max_delta_step=None,\n",
       "                                      max_depth=3, min_child_weight=None,\n",
       "                                      missing=nan, monotone_constraints=None,\n",
       "                                      n_estimators=100, n_job...\n",
       "                             'iterations': Integer(low=10, high=400, prior='uniform', transform='identity'),\n",
       "                             'learning_rate': Real(low=0.01, high=1.0, prior='log-uniform', transform='identity'),\n",
       "                             'max_depth': Integer(low=3, high=8, prior='uniform', transform='identity'),\n",
       "                             'n_estimators': Integer(low=100, high=300, prior='uniform', transform='identity'),\n",
       "                             'subsample': Real(low=0.1, high=1.0, prior='uniform', transform='identity')})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "xgb1 = XGBClassifier(max_depth=3,learning_rate=0.1, alpha=0, colsample_bytree = 0.5,\n",
    "                     subsample=0.1,n_estimators=100,gamma=0)\n",
    "\n",
    "param = {\n",
    "    'iterations': Integer(10, 400),uuuuuuu\n",
    "    'max_depth': Integer(3, 8, 'uniform'),\n",
    "    'learning_rate': Real(0.01, 0.3, 'log-uniform'),\n",
    "    'alpha': Real(0, 10.0, 'uniform'),\n",
    "    'colsample_bytree' : Real(0.5,1.0, 'uniform'),\n",
    "    'subsample': Real(0.1, 1.0, 'uniform'),\n",
    "    'n_estimators': Integer(100, 300, 'uniform'),\n",
    "    'gamma': Real(0, 10.0, 'uniform')\n",
    "}\n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_x = BayesSearchCV(\n",
    "    xgb1,\n",
    "    param,\n",
    "    scoring = LogLoss,\n",
    "    n_iter=40,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# executes bayesian optimization\n",
    "opt_x.fit(df_xgb, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5349627176835216e-06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_x.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('alpha', 0.0),\n",
       "             ('colsample_bytree', 1.0),\n",
       "             ('gamma', 0.0),\n",
       "             ('iterations', 400),\n",
       "             ('learning_rate', 0.27950642975302614),\n",
       "             ('max_depth', 5),\n",
       "             ('n_estimnators', 100),\n",
       "             ('subsample', 1.0)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_x.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJ5rpQL_mL37"
   },
   "source": [
    "### optimal lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayqcsmp8eeIQ"
   },
   "outputs": [],
   "source": [
    "df_lgb = df_train.copy()\n",
    "\n",
    "def convert_obj_to_int(self):\n",
    "    \n",
    "    object_list_columns = self.columns\n",
    "    object_list_dtypes = self.dtypes\n",
    "    new_col_suffix = '_int'\n",
    "    for index in range(0,len(object_list_columns)):\n",
    "        if object_list_dtypes[index] == object :\n",
    "            self[object_list_columns[index]+new_col_suffix] = self[object_list_columns[index]].map( lambda  x: hash(x))\n",
    "            self.drop([object_list_columns[index]],inplace=True,axis=1)\n",
    "    return self\n",
    "\n",
    "df_lgb = convert_obj_to_int(df_lgb)\n",
    "cut_off = int(len(df_lgb) * 0.7)\n",
    "X_train_lgb = df_lgb.iloc[:cut_off, :]\n",
    "X_test_lgb = df_lgb.iloc[cut_off:, :]\n",
    "y_train_lgb = Y_train[:cut_off]\n",
    "y_test_lgb = Y_train[cut_off:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jF0qHzxqmssd"
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer, auc, log_loss, roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# categorical_f = [ca for ca in X_train.columns if X_train[ca].dtype == 'object']\n",
    "lgb_model = lgb.LGBMClassifier(boosting_type='gbdt', objective='binary', metric='binary_logloss', bagging_freq=5)\n",
    "\n",
    "param = {\n",
    "    'max_depth': Integer(3, 7),\n",
    "    'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "    'feature_fraction': Real(0.2, 0.9, 'uniform'),\n",
    "    'bagging_fraction': Real(0.2, 0.9, 'log-uniform'),\n",
    "    'max_bin': Integer(20, 255, 'uniform'),\n",
    "    'n_estimators': Integer(100, 1000, 'uniform'),\n",
    "    'num_leaves': Integer(24, 80, 'uniform'),\n",
    "    'min_sum_hessian_in_leaf':Integer(0,100, 'uniform'),\n",
    "}\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_l = BayesSearchCV(\n",
    "    lgb_model,\n",
    "    param,\n",
    "    scoring = LogLoss,\n",
    "    n_iter=32,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "# executes bayesian optimization\n",
    "opt_l.fit(df_lgb, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "def convert_obj_to_int(self):\n",
    "    \n",
    "    object_list_columns = self.columns\n",
    "    object_list_dtypes = self.dtypes\n",
    "    new_col_suffix = '_int'\n",
    "    for index in range(0,len(object_list_columns)):\n",
    "        if object_list_dtypes[index] == object :\n",
    "            self[object_list_columns[index]+new_col_suffix] = self[object_list_columns[index]].map( lambda  x: hash(x))\n",
    "            self.drop([object_list_columns[index]],inplace=True,axis=1)\n",
    "    return self\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt = df_train.copy()\n",
    "df_opt_2 = df_train.copy()\n",
    "unused_cols = ['site_id', 'click']\n",
    "df_opt.drop(unused_cols, axis=1, inplace=True)\n",
    "df_opt_2.drop(unused_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p_c = {\n",
    "    'iterations': 400,\n",
    "    'depth': 8,\n",
    "    'learning_rate': 0.03,\n",
    "    'random_strength': 1e-09,\n",
    "    'bagging_temperature': 0.0,\n",
    "    'border_count': 48,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'scale_pos_weight':1.0\n",
    "}\n",
    "\n",
    "best_p_x = {\n",
    "    'alpha':0.0,\n",
    "    'colsample_bytree':1.0,\n",
    "    'gamma':0.0,\n",
    "    'iterations':400,\n",
    "    'learning_rate':0.27950642975302614,\n",
    "    'max_depth':5,\n",
    "    'n_estimators':100,\n",
    "    'subsample':1.0\n",
    "}\n",
    "\n",
    "\n",
    "best_p_l = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 5, \n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.11304216699488043,\n",
    "    'feature_fraction': 0.5066204305086464,\n",
    "    'bagging_fraction': 0.6657456066570288,\n",
    "    'max_bin': 188,\n",
    "    'n_estimators': 482,\n",
    "    'num_leaves': 60,\n",
    "    'min_sum_hessian_in_leaf':72\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.40328000650182544\n",
      "[11:39:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:39:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[11:57:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:57:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[12:15:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:15:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[12:31:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:31:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[12:48:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:48:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[13:06:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:06:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[13:24:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[13:40:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:40:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[13:57:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:57:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n",
      "1 0.40328000650182544\n",
      "[14:15:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function, n_estimnators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:15:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1 0.42108933834823564\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=72, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=72\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5066204305086464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5066204305086464\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657456066570288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657456066570288\n",
      "1 0.4175592359191733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# preds = np.zeros(test.shape[0])\n",
    "logloss_c=[]\n",
    "logloss_x=[]  # list contains rmse for each fold\n",
    "logloss_l=[]\n",
    "proba_cat_li=[]\n",
    "proba_xgb_li=[]\n",
    "proba_lgb_li=[]\n",
    "y_li = []\n",
    "n=0\n",
    "df_opt = convert_obj_to_int(df_opt)\n",
    "\n",
    "categorical_f = ['C1', 'banner_pos','site_domain','site_category','device_id','device_ip','device_model',\n",
    "                 'device_type','device_conn_type', 'C14','C15','C16','C17','C18', 'C19','C20','C21',\n",
    "                 'day_of_week', 'user', 'click_history']\n",
    "\n",
    "kf = KFold(n_splits=10,random_state=42,shuffle=False)\n",
    "#     preds+=xgb.predict(test[columns])/kf.n_splits\n",
    "for train_idx, test_idx in kf.split(df_opt,Y_train):\n",
    "    X_tr,X_val=df_opt_2.iloc[train_idx],df_opt_2.iloc[test_idx]\n",
    "    y_tr,y_val=Y_train.iloc[train_idx],Y_train.iloc[test_idx]\n",
    "    \n",
    "    X_tr_hash,X_val_hash=df_opt.iloc[train_idx],df_opt.iloc[test_idx]\n",
    "    \n",
    "    cat = CatBoostClassifier(**best_p_c,od_type='Iter', loss_function='Logloss', cat_features=categorical_f)\n",
    "    cat.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n",
    "    proba_cat = cat.predict_proba(X_val.values)[:, 1]\n",
    "    proba_cat_li.append(proba_cat)\n",
    "    logloss_c.append(log_loss(y_val, proba_cat))\n",
    "    print(n+1,logloss_c[n])\n",
    "    \n",
    "    xgb = XGBClassifier(**best_p_x, loss_function='Logloss')\n",
    "    xgb.fit(X_tr_hash,y_tr,eval_set=[(X_val_hash,y_val)],early_stopping_rounds=100,verbose=False)\n",
    "    proba_xgb = xgb.predict_proba(X_val_hash.values)[:, 1]\n",
    "    proba_xgb_li.append(proba_xgb)\n",
    "    logloss_x.append(log_loss(y_val, proba_xgb))\n",
    "    print(n+1,logloss_x[n])\n",
    "    \n",
    "    import lightgbm as lgb\n",
    "    lgb = lgb.LGBMClassifier(**best_p_l, loss_function='Logloss')\n",
    "    lgb.fit(X_tr_hash,y_tr,eval_set=[(X_val_hash,y_val)],early_stopping_rounds=100, verbose=False)\n",
    "    proba_lgb = lgb.predict_proba(X_val_hash.values)[:, 1]\n",
    "    proba_lgb_li.append(proba_lgb)\n",
    "    logloss_l.append(log_loss(y_val, proba_lgb))\n",
    "    print(n+1,logloss_l[n])\n",
    "    n+=1\n",
    "    \n",
    "    y_li.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "1 0.4223209824421238\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "2 0.4133231589949397\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "3 0.3980092164888491\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "4 0.3923824522567316\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "5 0.4145008562357522\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "6 0.4071268200114227\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "7 0.40979773100012995\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "8 0.44364494685921424\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.45178972523917776\n",
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=34, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=34\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.027647813535458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.027647813535458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6186329542584896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6186329542584896\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686771918501543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686771918501543\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.230523285313312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.230523285313312\n",
      "10 0.45605539870490774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# preds = np.zeros(test.shape[0])\n",
    "logloss_l=[]\n",
    "proba_lgb_li=[]\n",
    "y_li = []\n",
    "n=0\n",
    "df_opt = convert_obj_to_int(df_opt)\n",
    "\n",
    "categorical_f = ['C1', 'banner_pos','site_domain','site_category','device_id','device_ip','device_model',\n",
    "                 'device_type','device_conn_type', 'C14','C15','C16','C17','C18', 'C19','C20','C21',\n",
    "                 'day_of_week', 'user', 'click_history']\n",
    "\n",
    "kf = KFold(n_splits=10,random_state=42,shuffle=False)\n",
    "#     preds+=xgb.predict(test[columns])/kf.n_splits\n",
    "for train_idx, test_idx in kf.split(df_opt,Y_train):\n",
    "    X_tr,X_val=df_opt_2.iloc[train_idx],df_opt_2.iloc[test_idx]\n",
    "    y_tr,y_val=Y_train.iloc[train_idx],Y_train.iloc[test_idx]\n",
    "    \n",
    "    X_tr_hash,X_val_hash=df_opt.iloc[train_idx],df_opt.iloc[test_idx]\n",
    "    \n",
    "    import lightgbm as lgb\n",
    "    lgb = lgb.LGBMClassifier(**best_p_l_1, loss_function='Logloss')\n",
    "    lgb.fit(X_tr_hash,y_tr,eval_set=[(X_val_hash,y_val)],early_stopping_rounds=100, verbose=False)\n",
    "    proba_lgb = lgb.predict_proba(X_val_hash.values)[:, 1]\n",
    "    proba_lgb_li.append(proba_lgb)\n",
    "    logloss_l.append(log_loss(y_val, proba_lgb))\n",
    "    print(n+1,logloss_l[n])\n",
    "    n+=1\n",
    "    \n",
    "    y_li.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4223801857487906,\n",
       " 0.4130685394531392,\n",
       " 0.39848498070879224,\n",
       " 0.39233600311870004,\n",
       " 0.4142523146386964,\n",
       " 0.40700336273515536,\n",
       " 0.4097768056092878,\n",
       " 0.4436535687588471,\n",
       " 0.45154139665317516,\n",
       " 0.4565230681876022]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat 4\n",
      "xgb 4\n",
      "lgb 4\n",
      "y 4\n",
      "cat 5\n",
      "xgb 5\n",
      "lgb 5\n",
      "y 5\n",
      "cat 6\n",
      "xgb 6\n",
      "lgb 6\n",
      "y 6\n",
      "cat 7\n",
      "xgb 7\n",
      "lgb 7\n",
      "y 7\n",
      "cat 8\n",
      "xgb 8\n",
      "lgb 8\n",
      "y 8\n",
      "cat 9\n",
      "xgb 9\n",
      "lgb 9\n",
      "y 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if len(proba_cat_li[i]) == 205108:\n",
    "        print('cat', str(i))\n",
    "    if len(proba_xgb_li[i]) == 205108:\n",
    "        print('xgb', str(i))\n",
    "    if len(proba_lgb_li[i]) == 205108:\n",
    "        print('lgb', str(i))\n",
    "    if len(y_li[i]) == 205108:\n",
    "        print('y', str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_range = [0.001, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\n",
    "       0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of models in Catboost, xgboost, lightgbm\n",
    "model_num = 3\n",
    "# from the previous 10 folds\n",
    "cv_num = 10\n",
    "# create placeholder for results table\n",
    "output_wts_li = []\n",
    "for i in range(cv_num):\n",
    "    output_wts = np.zeros((len(X_val)+1, model_num+1))\n",
    "    output_wts_li.append(output_wts)\n",
    "\n",
    "# getting the possible weights for three models\n",
    "import itertools\n",
    "for i in range(cv_num):\n",
    "    j=0\n",
    "    for a,b,c in itertools.product(weights_range, repeat=model_num):\n",
    "        #get combination of weights, sum to 100%\n",
    "        sum_w = np.array([a,b,c]).sum()\n",
    "        wts = np.array([a,b,c]) / sum_w\n",
    "        if i>=4 and i<=9:\n",
    "            final_proba = np.zeros((len(X_val), ))\n",
    "        else:\n",
    "            final_proba = np.zeros((len(X_val)+1, ))\n",
    "        #get oof combination for weighted final_probability\n",
    "        final_proba+=proba_cat_li[i] * wts[0]\n",
    "        final_proba+=proba_xgb_li[i] * wts[1]\n",
    "        final_proba+=proba_lgb_li[i] * wts[2]\n",
    "\n",
    "        #get the logloss of weighted probability for i-fold\n",
    "        output_wts_li[i][j,model_num] = log_loss(y_li[i], final_proba)\n",
    "\n",
    "        #record the associated weights\n",
    "        output_wts_li[i][j,0:model_num] = wts\n",
    "\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.00199203, 0.00199203, 0.99601594, 0.42239416]),\n",
       " array([0.00181159, 0.00181159, 0.99637681, 0.42239251]),\n",
       " array([0.00166113, 0.00166113, 0.99667774, 0.42239119]),\n",
       " array([0.00153374, 0.00153374, 0.99693252, 0.42239012]),\n",
       " array([0.0014245 , 0.0014245 , 0.997151  , 0.42238922]),\n",
       " array([0.00132979, 0.00132979, 0.99734043, 0.42238847]),\n",
       " array([0.00124688, 0.00124688, 0.99750623, 0.42238783]),\n",
       " array([0.00117371, 0.00117371, 0.99765258, 0.42238728]),\n",
       " array([0.00110865, 0.00110865, 0.99778271, 0.4223868 ]),\n",
       " array([0.00105042, 0.00105042, 0.99789916, 0.42238638]),\n",
       " array([0.000999  , 0.000999  , 0.998002  , 0.42238601])]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def take_third(elem):\n",
    "    return elem[3]\n",
    "sorted(output_wts_li[0], key=take_third, reverse=True)[9250:9261]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.00199203, 0.00199203, 0.99601594, 0.44369035]),\n",
       " array([0.00181159, 0.00181159, 0.99637681, 0.44368664]),\n",
       " array([0.00166113, 0.00166113, 0.99667774, 0.44368361]),\n",
       " array([0.00153374, 0.00153374, 0.99693252, 0.44368107]),\n",
       " array([0.0014245 , 0.0014245 , 0.997151  , 0.44367893]),\n",
       " array([0.00132979, 0.00132979, 0.99734043, 0.44367709]),\n",
       " array([0.00124688, 0.00124688, 0.99750623, 0.4436755 ]),\n",
       " array([0.00117371, 0.00117371, 0.99765258, 0.44367411]),\n",
       " array([0.00110865, 0.00110865, 0.99778271, 0.44367288]),\n",
       " array([0.00105042, 0.00105042, 0.99789916, 0.44367179]),\n",
       " array([0.000999  , 0.000999  , 0.998002  , 0.44367084]),\n",
       " array([0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(output_wts_li[7], key=take_third, reverse=True)[9250:9262]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SJ_test (mock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sj = pd.read_csv(\"sj_test.gz\", compression='gzip', header='infer')\n",
    "Y_test = df_sj['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_cols_2 = ['site_id', 'click', 'user', 'click_history', 'day_of_week', 'device_ip_count', 'hour_count', \n",
    "                 'hourly_user_count']\n",
    "df_sj.drop(unused_cols, axis=1, inplace=True)\n",
    "categorical_f_2 = ['C1', 'banner_pos','site_domain','site_category','device_id','device_ip','device_model',\n",
    "                 'device_type','device_conn_type', 'C14','C15','C16','C17','C18', 'C19','C20','C21',\n",
    "                     ]\n",
    "unused_cols = ['site_id', 'click']\n",
    "categorical_f = ['C1', 'banner_pos','site_domain','site_category','device_id','device_ip','device_model',\n",
    "                 'device_type','device_conn_type', 'C14','C15','C16','C17','C18', 'C19','C20','C21',\n",
    "                 'day_of_week', 'user', 'click_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_train.copy()\n",
    "df_copy.drop(unused_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2051084 entries, 0 to 2051083\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   hour               int64 \n",
      " 1   C1                 int64 \n",
      " 2   banner_pos         int64 \n",
      " 3   site_domain        object\n",
      " 4   site_category      object\n",
      " 5   device_id          object\n",
      " 6   device_ip          object\n",
      " 7   device_model       object\n",
      " 8   device_type        int64 \n",
      " 9   device_conn_type   int64 \n",
      " 10  C14                int64 \n",
      " 11  C15                int64 \n",
      " 12  C16                int64 \n",
      " 13  C17                int64 \n",
      " 14  C18                int64 \n",
      " 15  C19                int64 \n",
      " 16  C20                int64 \n",
      " 17  C21                int64 \n",
      " 18  day_of_week        int64 \n",
      " 19  device_ip_count    int64 \n",
      " 20  device_id_count    int64 \n",
      " 21  hour_count         int64 \n",
      " 22  user               object\n",
      " 23  hourly_user_count  int64 \n",
      " 24  click_history      object\n",
      "dtypes: int64(18), object(7)\n",
      "memory usage: 391.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6869958\ttotal: 6.44s\tremaining: 53m 32s\n",
      "1:\tlearn: 0.6809918\ttotal: 12.8s\tremaining: 53m 2s\n",
      "2:\tlearn: 0.6751979\ttotal: 18s\tremaining: 49m 34s\n",
      "3:\tlearn: 0.6695498\ttotal: 22.8s\tremaining: 47m 5s\n",
      "4:\tlearn: 0.6639845\ttotal: 28.4s\tremaining: 46m 52s\n",
      "5:\tlearn: 0.6586140\ttotal: 33.5s\tremaining: 45m 54s\n",
      "6:\tlearn: 0.6533110\ttotal: 39.1s\tremaining: 45m 54s\n",
      "7:\tlearn: 0.6483074\ttotal: 45.6s\tremaining: 46m 45s\n",
      "8:\tlearn: 0.6433872\ttotal: 50.8s\tremaining: 46m 8s\n",
      "9:\tlearn: 0.6384648\ttotal: 56.4s\tremaining: 46m 4s\n",
      "10:\tlearn: 0.6338574\ttotal: 1m 1s\tremaining: 45m 55s\n",
      "11:\tlearn: 0.6290912\ttotal: 1m 7s\tremaining: 45m 26s\n",
      "12:\tlearn: 0.6246012\ttotal: 1m 12s\tremaining: 45m 33s\n",
      "13:\tlearn: 0.6200531\ttotal: 1m 17s\tremaining: 44m 43s\n",
      "14:\tlearn: 0.6157896\ttotal: 1m 23s\tremaining: 44m 59s\n",
      "15:\tlearn: 0.6116219\ttotal: 1m 28s\tremaining: 44m 43s\n",
      "16:\tlearn: 0.6074336\ttotal: 1m 33s\tremaining: 44m 26s\n",
      "17:\tlearn: 0.6033532\ttotal: 1m 38s\tremaining: 44m 9s\n",
      "18:\tlearn: 0.5993782\ttotal: 1m 43s\tremaining: 43m 50s\n",
      "19:\tlearn: 0.5956290\ttotal: 1m 49s\tremaining: 43m 42s\n",
      "20:\tlearn: 0.5918514\ttotal: 1m 54s\tremaining: 43m 24s\n",
      "21:\tlearn: 0.5883233\ttotal: 1m 59s\tremaining: 43m 17s\n",
      "22:\tlearn: 0.5848925\ttotal: 2m 5s\tremaining: 43m 20s\n",
      "23:\tlearn: 0.5815274\ttotal: 2m 11s\tremaining: 43m 27s\n",
      "24:\tlearn: 0.5782020\ttotal: 2m 16s\tremaining: 43m 18s\n",
      "25:\tlearn: 0.5750081\ttotal: 2m 22s\tremaining: 43m 9s\n",
      "26:\tlearn: 0.5718665\ttotal: 2m 27s\tremaining: 43m 2s\n",
      "27:\tlearn: 0.5688508\ttotal: 2m 32s\tremaining: 42m 55s\n",
      "28:\tlearn: 0.5658367\ttotal: 2m 38s\tremaining: 42m 46s\n",
      "29:\tlearn: 0.5629532\ttotal: 2m 43s\tremaining: 42m 36s\n",
      "30:\tlearn: 0.5600685\ttotal: 2m 48s\tremaining: 42m 25s\n",
      "31:\tlearn: 0.5573202\ttotal: 2m 53s\tremaining: 42m 24s\n",
      "32:\tlearn: 0.5546010\ttotal: 2m 58s\tremaining: 42m 11s\n",
      "33:\tlearn: 0.5519259\ttotal: 3m 4s\tremaining: 42m 11s\n",
      "34:\tlearn: 0.5493740\ttotal: 3m 9s\tremaining: 42m 2s\n",
      "35:\tlearn: 0.5468265\ttotal: 3m 15s\tremaining: 42m 1s\n",
      "36:\tlearn: 0.5443828\ttotal: 3m 20s\tremaining: 41m 48s\n",
      "37:\tlearn: 0.5420136\ttotal: 3m 26s\tremaining: 41m 48s\n",
      "38:\tlearn: 0.5396446\ttotal: 3m 32s\tremaining: 41m 56s\n",
      "39:\tlearn: 0.5373318\ttotal: 3m 38s\tremaining: 41m 54s\n",
      "40:\tlearn: 0.5351319\ttotal: 3m 44s\tremaining: 41m 48s\n",
      "41:\tlearn: 0.5329360\ttotal: 3m 50s\tremaining: 41m 49s\n",
      "42:\tlearn: 0.5308003\ttotal: 3m 56s\tremaining: 41m 54s\n",
      "43:\tlearn: 0.5287152\ttotal: 4m 2s\tremaining: 41m 54s\n",
      "44:\tlearn: 0.5267251\ttotal: 4m 7s\tremaining: 41m 46s\n",
      "45:\tlearn: 0.5247834\ttotal: 4m 13s\tremaining: 41m 44s\n",
      "46:\tlearn: 0.5228926\ttotal: 4m 19s\tremaining: 41m 40s\n",
      "47:\tlearn: 0.5210670\ttotal: 4m 25s\tremaining: 41m 38s\n",
      "48:\tlearn: 0.5192172\ttotal: 4m 30s\tremaining: 41m 29s\n",
      "49:\tlearn: 0.5174459\ttotal: 4m 36s\tremaining: 41m 27s\n",
      "50:\tlearn: 0.5156780\ttotal: 4m 41s\tremaining: 41m 22s\n",
      "51:\tlearn: 0.5139536\ttotal: 4m 48s\tremaining: 41m 25s\n",
      "52:\tlearn: 0.5122763\ttotal: 4m 54s\tremaining: 41m 21s\n",
      "53:\tlearn: 0.5106240\ttotal: 5m\tremaining: 41m 20s\n",
      "54:\tlearn: 0.5090387\ttotal: 5m 6s\tremaining: 41m 17s\n",
      "55:\tlearn: 0.5074259\ttotal: 5m 12s\tremaining: 41m 17s\n",
      "56:\tlearn: 0.5058398\ttotal: 5m 17s\tremaining: 41m 9s\n",
      "57:\tlearn: 0.5043161\ttotal: 5m 22s\tremaining: 40m 55s\n",
      "58:\tlearn: 0.5028648\ttotal: 5m 28s\tremaining: 40m 55s\n",
      "59:\tlearn: 0.5014120\ttotal: 5m 32s\tremaining: 40m 40s\n",
      "60:\tlearn: 0.5000389\ttotal: 5m 38s\tremaining: 40m 33s\n",
      "61:\tlearn: 0.4986352\ttotal: 5m 42s\tremaining: 40m 20s\n",
      "62:\tlearn: 0.4971812\ttotal: 5m 47s\tremaining: 40m 10s\n",
      "63:\tlearn: 0.4954809\ttotal: 5m 53s\tremaining: 40m 11s\n",
      "64:\tlearn: 0.4938867\ttotal: 6m\tremaining: 40m 11s\n",
      "65:\tlearn: 0.4923327\ttotal: 6m 6s\tremaining: 40m 9s\n",
      "66:\tlearn: 0.4907815\ttotal: 6m 11s\tremaining: 40m 4s\n",
      "67:\tlearn: 0.4893034\ttotal: 6m 17s\tremaining: 40m\n",
      "68:\tlearn: 0.4878278\ttotal: 6m 23s\tremaining: 39m 54s\n",
      "69:\tlearn: 0.4863895\ttotal: 6m 28s\tremaining: 39m 47s\n",
      "70:\tlearn: 0.4850219\ttotal: 6m 34s\tremaining: 39m 41s\n",
      "71:\tlearn: 0.4836850\ttotal: 6m 39s\tremaining: 39m 36s\n",
      "72:\tlearn: 0.4823569\ttotal: 6m 44s\tremaining: 39m 28s\n",
      "73:\tlearn: 0.4810855\ttotal: 6m 50s\tremaining: 39m 23s\n",
      "74:\tlearn: 0.4798367\ttotal: 6m 55s\tremaining: 39m 13s\n",
      "75:\tlearn: 0.4786050\ttotal: 7m\tremaining: 39m 7s\n",
      "76:\tlearn: 0.4773933\ttotal: 7m 5s\tremaining: 38m 59s\n",
      "77:\tlearn: 0.4762135\ttotal: 7m 11s\tremaining: 38m 52s\n",
      "78:\tlearn: 0.4750914\ttotal: 7m 17s\tremaining: 38m 50s\n",
      "79:\tlearn: 0.4739969\ttotal: 7m 23s\tremaining: 38m 48s\n",
      "80:\tlearn: 0.4728995\ttotal: 7m 28s\tremaining: 38m 39s\n",
      "81:\tlearn: 0.4718804\ttotal: 7m 30s\tremaining: 38m 17s\n",
      "82:\tlearn: 0.4708326\ttotal: 7m 35s\tremaining: 38m 9s\n",
      "83:\tlearn: 0.4698375\ttotal: 7m 42s\tremaining: 38m 9s\n",
      "84:\tlearn: 0.4688388\ttotal: 7m 48s\tremaining: 38m 5s\n",
      "85:\tlearn: 0.4678786\ttotal: 7m 54s\tremaining: 38m 2s\n",
      "86:\tlearn: 0.4669417\ttotal: 7m 59s\tremaining: 37m 56s\n",
      "87:\tlearn: 0.4660308\ttotal: 8m 5s\tremaining: 37m 51s\n",
      "88:\tlearn: 0.4651375\ttotal: 8m 10s\tremaining: 37m 46s\n",
      "89:\tlearn: 0.4642619\ttotal: 8m 16s\tremaining: 37m 41s\n",
      "90:\tlearn: 0.4633920\ttotal: 8m 22s\tremaining: 37m 37s\n",
      "91:\tlearn: 0.4625927\ttotal: 8m 27s\tremaining: 37m 32s\n",
      "92:\tlearn: 0.4617589\ttotal: 8m 32s\tremaining: 37m 24s\n",
      "93:\tlearn: 0.4609161\ttotal: 8m 37s\tremaining: 37m 16s\n",
      "94:\tlearn: 0.4601495\ttotal: 8m 43s\tremaining: 37m 12s\n",
      "95:\tlearn: 0.4593973\ttotal: 8m 49s\tremaining: 37m 10s\n",
      "96:\tlearn: 0.4586118\ttotal: 8m 55s\tremaining: 37m 5s\n",
      "97:\tlearn: 0.4578870\ttotal: 9m 2s\tremaining: 37m 3s\n",
      "98:\tlearn: 0.4571855\ttotal: 9m 7s\tremaining: 36m 58s\n",
      "99:\tlearn: 0.4564682\ttotal: 9m 13s\tremaining: 36m 53s\n",
      "100:\tlearn: 0.4558259\ttotal: 9m 18s\tremaining: 36m 47s\n",
      "101:\tlearn: 0.4552099\ttotal: 9m 24s\tremaining: 36m 40s\n",
      "102:\tlearn: 0.4545905\ttotal: 9m 29s\tremaining: 36m 33s\n",
      "103:\tlearn: 0.4539854\ttotal: 9m 34s\tremaining: 36m 28s\n",
      "104:\tlearn: 0.4533661\ttotal: 9m 41s\tremaining: 36m 26s\n",
      "105:\tlearn: 0.4527197\ttotal: 9m 47s\tremaining: 36m 22s\n",
      "106:\tlearn: 0.4521540\ttotal: 9m 53s\tremaining: 36m 18s\n",
      "107:\tlearn: 0.4515965\ttotal: 9m 58s\tremaining: 36m 12s\n",
      "108:\tlearn: 0.4510547\ttotal: 10m 4s\tremaining: 36m 7s\n",
      "109:\tlearn: 0.4504592\ttotal: 10m 10s\tremaining: 36m 2s\n",
      "110:\tlearn: 0.4499460\ttotal: 10m 16s\tremaining: 36m\n",
      "111:\tlearn: 0.4493676\ttotal: 10m 21s\tremaining: 35m 54s\n",
      "112:\tlearn: 0.4488034\ttotal: 10m 28s\tremaining: 35m 51s\n",
      "113:\tlearn: 0.4483236\ttotal: 10m 32s\tremaining: 35m 40s\n",
      "114:\tlearn: 0.4477855\ttotal: 10m 37s\tremaining: 35m 32s\n",
      "115:\tlearn: 0.4473136\ttotal: 10m 42s\tremaining: 35m 27s\n",
      "116:\tlearn: 0.4468526\ttotal: 10m 48s\tremaining: 35m 23s\n",
      "117:\tlearn: 0.4463607\ttotal: 10m 54s\tremaining: 35m 20s\n",
      "118:\tlearn: 0.4459261\ttotal: 11m\tremaining: 35m 15s\n",
      "119:\tlearn: 0.4454927\ttotal: 11m 5s\tremaining: 35m 6s\n",
      "120:\tlearn: 0.4450310\ttotal: 11m 12s\tremaining: 35m 5s\n",
      "121:\tlearn: 0.4446288\ttotal: 11m 16s\tremaining: 34m 56s\n",
      "122:\tlearn: 0.4442254\ttotal: 11m 23s\tremaining: 34m 55s\n",
      "123:\tlearn: 0.4437814\ttotal: 11m 30s\tremaining: 34m 54s\n",
      "124:\tlearn: 0.4433918\ttotal: 11m 35s\tremaining: 34m 45s\n",
      "125:\tlearn: 0.4429753\ttotal: 11m 40s\tremaining: 34m 40s\n",
      "126:\tlearn: 0.4425571\ttotal: 11m 47s\tremaining: 34m 38s\n",
      "127:\tlearn: 0.4422036\ttotal: 11m 52s\tremaining: 34m 31s\n",
      "128:\tlearn: 0.4417965\ttotal: 11m 58s\tremaining: 34m 25s\n",
      "129:\tlearn: 0.4414414\ttotal: 12m 3s\tremaining: 34m 19s\n",
      "130:\tlearn: 0.4410579\ttotal: 12m 9s\tremaining: 34m 14s\n",
      "131:\tlearn: 0.4406906\ttotal: 12m 15s\tremaining: 34m 9s\n",
      "132:\tlearn: 0.4403248\ttotal: 12m 21s\tremaining: 34m 6s\n",
      "133:\tlearn: 0.4399671\ttotal: 12m 28s\tremaining: 34m 4s\n",
      "134:\tlearn: 0.4396198\ttotal: 12m 35s\tremaining: 34m 3s\n",
      "135:\tlearn: 0.4392615\ttotal: 12m 41s\tremaining: 33m 59s\n",
      "136:\tlearn: 0.4389127\ttotal: 12m 48s\tremaining: 33m 55s\n",
      "137:\tlearn: 0.4385718\ttotal: 12m 54s\tremaining: 33m 50s\n",
      "138:\tlearn: 0.4382527\ttotal: 13m 1s\tremaining: 33m 48s\n",
      "139:\tlearn: 0.4379140\ttotal: 13m 7s\tremaining: 33m 45s\n",
      "140:\tlearn: 0.4376041\ttotal: 13m 14s\tremaining: 33m 42s\n",
      "141:\tlearn: 0.4373010\ttotal: 13m 20s\tremaining: 33m 38s\n",
      "142:\tlearn: 0.4369915\ttotal: 13m 27s\tremaining: 33m 34s\n",
      "143:\tlearn: 0.4366994\ttotal: 13m 34s\tremaining: 33m 33s\n",
      "144:\tlearn: 0.4364025\ttotal: 13m 41s\tremaining: 33m 32s\n",
      "145:\tlearn: 0.4361014\ttotal: 13m 49s\tremaining: 33m 32s\n",
      "146:\tlearn: 0.4358229\ttotal: 13m 57s\tremaining: 33m 31s\n",
      "147:\tlearn: 0.4355445\ttotal: 14m 4s\tremaining: 33m 29s\n",
      "148:\tlearn: 0.4352800\ttotal: 14m 12s\tremaining: 33m 27s\n",
      "149:\tlearn: 0.4350056\ttotal: 14m 19s\tremaining: 33m 26s\n",
      "150:\tlearn: 0.4347528\ttotal: 14m 27s\tremaining: 33m 25s\n",
      "151:\tlearn: 0.4344963\ttotal: 14m 34s\tremaining: 33m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152:\tlearn: 0.4342519\ttotal: 14m 41s\tremaining: 33m 20s\n",
      "153:\tlearn: 0.4339809\ttotal: 14m 50s\tremaining: 33m 19s\n",
      "154:\tlearn: 0.4337345\ttotal: 14m 56s\tremaining: 33m 16s\n",
      "155:\tlearn: 0.4335050\ttotal: 15m 4s\tremaining: 33m 14s\n",
      "156:\tlearn: 0.4332431\ttotal: 15m 11s\tremaining: 33m 11s\n",
      "157:\tlearn: 0.4330109\ttotal: 15m 18s\tremaining: 33m 7s\n",
      "158:\tlearn: 0.4327719\ttotal: 15m 25s\tremaining: 33m 5s\n",
      "159:\tlearn: 0.4325607\ttotal: 15m 32s\tremaining: 33m 1s\n",
      "160:\tlearn: 0.4323352\ttotal: 15m 39s\tremaining: 32m 58s\n",
      "161:\tlearn: 0.4321260\ttotal: 15m 46s\tremaining: 32m 54s\n",
      "162:\tlearn: 0.4319216\ttotal: 15m 53s\tremaining: 32m 50s\n",
      "163:\tlearn: 0.4316911\ttotal: 15m 59s\tremaining: 32m 46s\n",
      "164:\tlearn: 0.4314821\ttotal: 16m 6s\tremaining: 32m 41s\n",
      "165:\tlearn: 0.4312149\ttotal: 16m 14s\tremaining: 32m 40s\n",
      "166:\tlearn: 0.4309646\ttotal: 16m 22s\tremaining: 32m 38s\n",
      "167:\tlearn: 0.4307197\ttotal: 16m 30s\tremaining: 32m 37s\n",
      "168:\tlearn: 0.4304570\ttotal: 16m 38s\tremaining: 32m 35s\n",
      "169:\tlearn: 0.4302221\ttotal: 16m 46s\tremaining: 32m 33s\n",
      "170:\tlearn: 0.4299879\ttotal: 16m 53s\tremaining: 32m 30s\n",
      "171:\tlearn: 0.4297688\ttotal: 17m 2s\tremaining: 32m 29s\n",
      "172:\tlearn: 0.4295474\ttotal: 17m 11s\tremaining: 32m 29s\n",
      "173:\tlearn: 0.4293353\ttotal: 17m 20s\tremaining: 32m 29s\n",
      "174:\tlearn: 0.4291293\ttotal: 17m 28s\tremaining: 32m 27s\n",
      "175:\tlearn: 0.4289274\ttotal: 17m 37s\tremaining: 32m 26s\n",
      "176:\tlearn: 0.4287186\ttotal: 17m 46s\tremaining: 32m 25s\n",
      "177:\tlearn: 0.4285239\ttotal: 17m 53s\tremaining: 32m 22s\n",
      "178:\tlearn: 0.4283333\ttotal: 18m 1s\tremaining: 32m 19s\n",
      "179:\tlearn: 0.4281470\ttotal: 18m 9s\tremaining: 32m 17s\n",
      "180:\tlearn: 0.4279615\ttotal: 18m 17s\tremaining: 32m 14s\n",
      "181:\tlearn: 0.4277827\ttotal: 18m 26s\tremaining: 32m 13s\n",
      "182:\tlearn: 0.4276047\ttotal: 18m 33s\tremaining: 32m 9s\n",
      "183:\tlearn: 0.4274142\ttotal: 18m 42s\tremaining: 32m 7s\n",
      "184:\tlearn: 0.4272092\ttotal: 18m 49s\tremaining: 32m 3s\n",
      "185:\tlearn: 0.4270264\ttotal: 18m 58s\tremaining: 32m 2s\n",
      "186:\tlearn: 0.4268704\ttotal: 19m 6s\tremaining: 31m 58s\n",
      "187:\tlearn: 0.4266761\ttotal: 19m 13s\tremaining: 31m 54s\n",
      "188:\tlearn: 0.4265251\ttotal: 19m 27s\tremaining: 32m 1s\n",
      "189:\tlearn: 0.4263740\ttotal: 19m 39s\tremaining: 32m 3s\n",
      "190:\tlearn: 0.4262212\ttotal: 19m 47s\tremaining: 32m 1s\n",
      "191:\tlearn: 0.4260655\ttotal: 19m 55s\tremaining: 31m 58s\n",
      "192:\tlearn: 0.4259006\ttotal: 20m 3s\tremaining: 31m 54s\n",
      "193:\tlearn: 0.4257426\ttotal: 20m 11s\tremaining: 31m 51s\n",
      "194:\tlearn: 0.4255710\ttotal: 20m 19s\tremaining: 31m 48s\n",
      "195:\tlearn: 0.4254106\ttotal: 20m 27s\tremaining: 31m 44s\n",
      "196:\tlearn: 0.4252440\ttotal: 20m 35s\tremaining: 31m 40s\n",
      "197:\tlearn: 0.4250955\ttotal: 20m 43s\tremaining: 31m 36s\n",
      "198:\tlearn: 0.4249440\ttotal: 20m 51s\tremaining: 31m 33s\n",
      "199:\tlearn: 0.4247957\ttotal: 20m 59s\tremaining: 31m 29s\n",
      "200:\tlearn: 0.4246494\ttotal: 21m 7s\tremaining: 31m 25s\n",
      "201:\tlearn: 0.4245008\ttotal: 21m 15s\tremaining: 31m 21s\n",
      "202:\tlearn: 0.4243755\ttotal: 21m 22s\tremaining: 31m 16s\n",
      "203:\tlearn: 0.4242510\ttotal: 21m 30s\tremaining: 31m 12s\n",
      "204:\tlearn: 0.4241135\ttotal: 21m 40s\tremaining: 31m 12s\n",
      "205:\tlearn: 0.4239843\ttotal: 22m\tremaining: 31m 25s\n",
      "206:\tlearn: 0.4238387\ttotal: 22m 11s\tremaining: 31m 24s\n",
      "207:\tlearn: 0.4237123\ttotal: 22m 20s\tremaining: 31m 21s\n",
      "208:\tlearn: 0.4235864\ttotal: 22m 29s\tremaining: 31m 19s\n",
      "209:\tlearn: 0.4234669\ttotal: 22m 39s\tremaining: 31m 16s\n",
      "210:\tlearn: 0.4233457\ttotal: 22m 47s\tremaining: 31m 13s\n",
      "211:\tlearn: 0.4232306\ttotal: 22m 56s\tremaining: 31m 9s\n",
      "212:\tlearn: 0.4230996\ttotal: 23m 3s\tremaining: 31m 4s\n",
      "213:\tlearn: 0.4229786\ttotal: 23m 11s\tremaining: 31m\n",
      "214:\tlearn: 0.4228633\ttotal: 23m 20s\tremaining: 30m 55s\n",
      "215:\tlearn: 0.4227641\ttotal: 23m 28s\tremaining: 30m 52s\n",
      "216:\tlearn: 0.4226655\ttotal: 23m 37s\tremaining: 30m 48s\n",
      "217:\tlearn: 0.4225809\ttotal: 23m 46s\tremaining: 30m 45s\n",
      "218:\tlearn: 0.4224632\ttotal: 23m 54s\tremaining: 30m 41s\n",
      "219:\tlearn: 0.4223668\ttotal: 24m 3s\tremaining: 30m 37s\n",
      "220:\tlearn: 0.4222726\ttotal: 24m 12s\tremaining: 30m 33s\n",
      "221:\tlearn: 0.4221689\ttotal: 24m 37s\tremaining: 30m 50s\n",
      "222:\tlearn: 0.4220812\ttotal: 24m 50s\tremaining: 30m 51s\n",
      "223:\tlearn: 0.4219727\ttotal: 24m 59s\tremaining: 30m 47s\n",
      "224:\tlearn: 0.4218660\ttotal: 25m 6s\tremaining: 30m 41s\n",
      "225:\tlearn: 0.4217663\ttotal: 25m 14s\tremaining: 30m 36s\n",
      "226:\tlearn: 0.4216803\ttotal: 25m 23s\tremaining: 30m 32s\n",
      "227:\tlearn: 0.4215830\ttotal: 25m 30s\tremaining: 30m 26s\n",
      "228:\tlearn: 0.4214879\ttotal: 25m 38s\tremaining: 30m 20s\n",
      "229:\tlearn: 0.4213944\ttotal: 25m 46s\tremaining: 30m 15s\n",
      "230:\tlearn: 0.4213011\ttotal: 25m 54s\tremaining: 30m 10s\n",
      "231:\tlearn: 0.4212108\ttotal: 26m 2s\tremaining: 30m 4s\n",
      "232:\tlearn: 0.4211306\ttotal: 26m 13s\tremaining: 30m 2s\n",
      "233:\tlearn: 0.4210593\ttotal: 26m 22s\tremaining: 29m 58s\n",
      "234:\tlearn: 0.4209726\ttotal: 26m 31s\tremaining: 29m 54s\n",
      "235:\tlearn: 0.4208847\ttotal: 26m 40s\tremaining: 29m 49s\n",
      "236:\tlearn: 0.4208013\ttotal: 26m 47s\tremaining: 29m 44s\n",
      "237:\tlearn: 0.4207197\ttotal: 26m 55s\tremaining: 29m 38s\n",
      "238:\tlearn: 0.4206338\ttotal: 27m 4s\tremaining: 29m 33s\n",
      "239:\tlearn: 0.4205573\ttotal: 27m 22s\tremaining: 29m 39s\n",
      "240:\tlearn: 0.4204813\ttotal: 27m 33s\tremaining: 29m 36s\n",
      "241:\tlearn: 0.4204049\ttotal: 27m 42s\tremaining: 29m 32s\n",
      "242:\tlearn: 0.4203301\ttotal: 27m 51s\tremaining: 29m 27s\n",
      "243:\tlearn: 0.4202543\ttotal: 27m 59s\tremaining: 29m 21s\n",
      "244:\tlearn: 0.4201854\ttotal: 28m 8s\tremaining: 29m 16s\n",
      "245:\tlearn: 0.4201157\ttotal: 28m 15s\tremaining: 29m 10s\n",
      "246:\tlearn: 0.4200581\ttotal: 28m 22s\tremaining: 29m 3s\n",
      "247:\tlearn: 0.4199893\ttotal: 28m 29s\tremaining: 28m 57s\n",
      "248:\tlearn: 0.4199186\ttotal: 28m 37s\tremaining: 28m 51s\n",
      "249:\tlearn: 0.4198581\ttotal: 28m 44s\tremaining: 28m 44s\n",
      "250:\tlearn: 0.4198039\ttotal: 28m 53s\tremaining: 28m 39s\n",
      "251:\tlearn: 0.4197436\ttotal: 29m 2s\tremaining: 28m 35s\n",
      "252:\tlearn: 0.4196744\ttotal: 29m 11s\tremaining: 28m 30s\n",
      "253:\tlearn: 0.4196095\ttotal: 29m 20s\tremaining: 28m 25s\n",
      "254:\tlearn: 0.4195413\ttotal: 29m 29s\tremaining: 28m 19s\n",
      "255:\tlearn: 0.4194690\ttotal: 29m 37s\tremaining: 28m 14s\n",
      "256:\tlearn: 0.4194033\ttotal: 29m 50s\tremaining: 28m 12s\n",
      "257:\tlearn: 0.4193390\ttotal: 30m 5s\tremaining: 28m 13s\n",
      "258:\tlearn: 0.4192617\ttotal: 30m 15s\tremaining: 28m 9s\n",
      "259:\tlearn: 0.4192026\ttotal: 30m 24s\tremaining: 28m 4s\n",
      "260:\tlearn: 0.4191419\ttotal: 30m 33s\tremaining: 27m 59s\n",
      "261:\tlearn: 0.4190851\ttotal: 30m 42s\tremaining: 27m 53s\n",
      "262:\tlearn: 0.4190126\ttotal: 30m 55s\tremaining: 27m 52s\n",
      "263:\tlearn: 0.4189460\ttotal: 31m 8s\tremaining: 27m 49s\n",
      "264:\tlearn: 0.4188808\ttotal: 31m 19s\tremaining: 27m 46s\n",
      "265:\tlearn: 0.4188148\ttotal: 31m 29s\tremaining: 27m 41s\n",
      "266:\tlearn: 0.4187512\ttotal: 31m 37s\tremaining: 27m 36s\n",
      "267:\tlearn: 0.4186826\ttotal: 31m 46s\tremaining: 27m 29s\n",
      "268:\tlearn: 0.4186157\ttotal: 31m 58s\tremaining: 27m 27s\n",
      "269:\tlearn: 0.4185501\ttotal: 32m 8s\tremaining: 27m 22s\n",
      "270:\tlearn: 0.4184983\ttotal: 32m 17s\tremaining: 27m 17s\n",
      "271:\tlearn: 0.4184346\ttotal: 32m 27s\tremaining: 27m 12s\n",
      "272:\tlearn: 0.4183640\ttotal: 32m 36s\tremaining: 27m 6s\n",
      "273:\tlearn: 0.4183013\ttotal: 32m 47s\tremaining: 27m 2s\n",
      "274:\tlearn: 0.4182399\ttotal: 32m 57s\tremaining: 26m 57s\n",
      "275:\tlearn: 0.4181763\ttotal: 33m 6s\tremaining: 26m 52s\n",
      "276:\tlearn: 0.4181196\ttotal: 33m 18s\tremaining: 26m 48s\n",
      "277:\tlearn: 0.4180641\ttotal: 33m 29s\tremaining: 26m 44s\n",
      "278:\tlearn: 0.4180037\ttotal: 33m 38s\tremaining: 26m 38s\n",
      "279:\tlearn: 0.4179450\ttotal: 33m 49s\tremaining: 26m 34s\n",
      "280:\tlearn: 0.4178972\ttotal: 34m 4s\tremaining: 26m 33s\n",
      "281:\tlearn: 0.4178353\ttotal: 34m 14s\tremaining: 26m 28s\n",
      "282:\tlearn: 0.4177813\ttotal: 34m 24s\tremaining: 26m 23s\n",
      "283:\tlearn: 0.4177234\ttotal: 34m 33s\tremaining: 26m 17s\n",
      "284:\tlearn: 0.4176722\ttotal: 34m 43s\tremaining: 26m 11s\n",
      "285:\tlearn: 0.4176275\ttotal: 34m 52s\tremaining: 26m 5s\n",
      "286:\tlearn: 0.4175744\ttotal: 35m 3s\tremaining: 26m 1s\n",
      "287:\tlearn: 0.4175302\ttotal: 35m 14s\tremaining: 25m 56s\n",
      "288:\tlearn: 0.4174868\ttotal: 35m 23s\tremaining: 25m 50s\n",
      "289:\tlearn: 0.4174317\ttotal: 35m 33s\tremaining: 25m 44s\n",
      "290:\tlearn: 0.4173768\ttotal: 35m 42s\tremaining: 25m 38s\n",
      "291:\tlearn: 0.4173290\ttotal: 35m 51s\tremaining: 25m 32s\n",
      "292:\tlearn: 0.4172849\ttotal: 36m 1s\tremaining: 25m 27s\n",
      "293:\tlearn: 0.4172369\ttotal: 36m 11s\tremaining: 25m 21s\n",
      "294:\tlearn: 0.4171892\ttotal: 36m 21s\tremaining: 25m 15s\n",
      "295:\tlearn: 0.4171430\ttotal: 36m 30s\tremaining: 25m 9s\n",
      "296:\tlearn: 0.4170937\ttotal: 36m 40s\tremaining: 25m 3s\n",
      "297:\tlearn: 0.4170516\ttotal: 36m 49s\tremaining: 24m 57s\n",
      "298:\tlearn: 0.4170148\ttotal: 36m 59s\tremaining: 24m 52s\n",
      "299:\tlearn: 0.4169668\ttotal: 37m 9s\tremaining: 24m 46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300:\tlearn: 0.4169271\ttotal: 37m 18s\tremaining: 24m 40s\n",
      "301:\tlearn: 0.4168884\ttotal: 37m 28s\tremaining: 24m 33s\n",
      "302:\tlearn: 0.4168543\ttotal: 37m 39s\tremaining: 24m 28s\n",
      "303:\tlearn: 0.4168199\ttotal: 37m 51s\tremaining: 24m 24s\n",
      "304:\tlearn: 0.4167836\ttotal: 38m\tremaining: 24m 18s\n",
      "305:\tlearn: 0.4167464\ttotal: 38m 10s\tremaining: 24m 12s\n",
      "306:\tlearn: 0.4167142\ttotal: 38m 19s\tremaining: 24m 5s\n",
      "307:\tlearn: 0.4166733\ttotal: 38m 29s\tremaining: 23m 59s\n",
      "308:\tlearn: 0.4166395\ttotal: 38m 39s\tremaining: 23m 54s\n",
      "309:\tlearn: 0.4165972\ttotal: 38m 49s\tremaining: 23m 47s\n",
      "310:\tlearn: 0.4165632\ttotal: 38m 58s\tremaining: 23m 41s\n",
      "311:\tlearn: 0.4165234\ttotal: 39m 7s\tremaining: 23m 34s\n",
      "312:\tlearn: 0.4164876\ttotal: 39m 20s\tremaining: 23m 30s\n",
      "313:\tlearn: 0.4164523\ttotal: 39m 29s\tremaining: 23m 23s\n",
      "314:\tlearn: 0.4164134\ttotal: 39m 38s\tremaining: 23m 17s\n",
      "315:\tlearn: 0.4163714\ttotal: 39m 48s\tremaining: 23m 10s\n",
      "316:\tlearn: 0.4163307\ttotal: 40m 2s\tremaining: 23m 6s\n",
      "317:\tlearn: 0.4163005\ttotal: 40m 13s\tremaining: 23m 1s\n",
      "318:\tlearn: 0.4162705\ttotal: 40m 30s\tremaining: 22m 59s\n",
      "319:\tlearn: 0.4162376\ttotal: 40m 41s\tremaining: 22m 53s\n",
      "320:\tlearn: 0.4162073\ttotal: 40m 52s\tremaining: 22m 47s\n",
      "321:\tlearn: 0.4161680\ttotal: 41m 3s\tremaining: 22m 41s\n",
      "322:\tlearn: 0.4161343\ttotal: 41m 13s\tremaining: 22m 35s\n",
      "323:\tlearn: 0.4161054\ttotal: 41m 21s\tremaining: 22m 28s\n",
      "324:\tlearn: 0.4160748\ttotal: 41m 31s\tremaining: 22m 21s\n",
      "325:\tlearn: 0.4160425\ttotal: 41m 40s\tremaining: 22m 14s\n",
      "326:\tlearn: 0.4160156\ttotal: 41m 51s\tremaining: 22m 8s\n",
      "327:\tlearn: 0.4159881\ttotal: 42m\tremaining: 22m 1s\n",
      "328:\tlearn: 0.4159524\ttotal: 42m 10s\tremaining: 21m 55s\n",
      "329:\tlearn: 0.4159181\ttotal: 42m 22s\tremaining: 21m 49s\n",
      "330:\tlearn: 0.4158926\ttotal: 42m 32s\tremaining: 21m 43s\n",
      "331:\tlearn: 0.4158667\ttotal: 42m 44s\tremaining: 21m 37s\n",
      "332:\tlearn: 0.4158406\ttotal: 42m 52s\tremaining: 21m 30s\n",
      "333:\tlearn: 0.4158151\ttotal: 43m\tremaining: 21m 22s\n",
      "334:\tlearn: 0.4157817\ttotal: 43m 10s\tremaining: 21m 15s\n",
      "335:\tlearn: 0.4157496\ttotal: 43m 18s\tremaining: 21m 8s\n",
      "336:\tlearn: 0.4157251\ttotal: 43m 27s\tremaining: 21m 1s\n",
      "337:\tlearn: 0.4157011\ttotal: 43m 35s\tremaining: 20m 53s\n",
      "338:\tlearn: 0.4156728\ttotal: 43m 44s\tremaining: 20m 46s\n",
      "339:\tlearn: 0.4156462\ttotal: 43m 53s\tremaining: 20m 39s\n",
      "340:\tlearn: 0.4156157\ttotal: 44m 2s\tremaining: 20m 32s\n",
      "341:\tlearn: 0.4155859\ttotal: 44m 10s\tremaining: 20m 24s\n",
      "342:\tlearn: 0.4155587\ttotal: 44m 24s\tremaining: 20m 19s\n",
      "343:\tlearn: 0.4155335\ttotal: 44m 33s\tremaining: 20m 12s\n",
      "344:\tlearn: 0.4155071\ttotal: 44m 44s\tremaining: 20m 6s\n",
      "345:\tlearn: 0.4154785\ttotal: 44m 53s\tremaining: 19m 58s\n",
      "346:\tlearn: 0.4154518\ttotal: 45m 5s\tremaining: 19m 53s\n",
      "347:\tlearn: 0.4154309\ttotal: 45m 14s\tremaining: 19m 45s\n",
      "348:\tlearn: 0.4154065\ttotal: 45m 23s\tremaining: 19m 38s\n",
      "349:\tlearn: 0.4153705\ttotal: 45m 34s\tremaining: 19m 31s\n",
      "350:\tlearn: 0.4153447\ttotal: 45m 44s\tremaining: 19m 25s\n",
      "351:\tlearn: 0.4153175\ttotal: 45m 55s\tremaining: 19m 18s\n",
      "352:\tlearn: 0.4152828\ttotal: 46m 5s\tremaining: 19m 11s\n",
      "353:\tlearn: 0.4152504\ttotal: 46m 14s\tremaining: 19m 4s\n",
      "354:\tlearn: 0.4152222\ttotal: 46m 26s\tremaining: 18m 58s\n",
      "355:\tlearn: 0.4151948\ttotal: 46m 35s\tremaining: 18m 50s\n",
      "356:\tlearn: 0.4151697\ttotal: 46m 44s\tremaining: 18m 43s\n",
      "357:\tlearn: 0.4151440\ttotal: 46m 52s\tremaining: 18m 35s\n",
      "358:\tlearn: 0.4151185\ttotal: 47m 1s\tremaining: 18m 28s\n",
      "359:\tlearn: 0.4150929\ttotal: 47m 9s\tremaining: 18m 20s\n",
      "360:\tlearn: 0.4150704\ttotal: 47m 18s\tremaining: 18m 12s\n",
      "361:\tlearn: 0.4150485\ttotal: 47m 27s\tremaining: 18m 5s\n",
      "362:\tlearn: 0.4150229\ttotal: 47m 36s\tremaining: 17m 57s\n",
      "363:\tlearn: 0.4150016\ttotal: 47m 45s\tremaining: 17m 50s\n",
      "364:\tlearn: 0.4149822\ttotal: 47m 54s\tremaining: 17m 43s\n",
      "365:\tlearn: 0.4149575\ttotal: 48m 2s\tremaining: 17m 35s\n",
      "366:\tlearn: 0.4149342\ttotal: 48m 12s\tremaining: 17m 28s\n",
      "367:\tlearn: 0.4149070\ttotal: 48m 21s\tremaining: 17m 20s\n",
      "368:\tlearn: 0.4148844\ttotal: 48m 31s\tremaining: 17m 13s\n",
      "369:\tlearn: 0.4148663\ttotal: 48m 41s\tremaining: 17m 6s\n",
      "370:\tlearn: 0.4148444\ttotal: 48m 51s\tremaining: 16m 59s\n",
      "371:\tlearn: 0.4148268\ttotal: 49m 1s\tremaining: 16m 52s\n",
      "372:\tlearn: 0.4148058\ttotal: 49m 12s\tremaining: 16m 45s\n",
      "373:\tlearn: 0.4147888\ttotal: 49m 22s\tremaining: 16m 38s\n",
      "374:\tlearn: 0.4147664\ttotal: 49m 32s\tremaining: 16m 30s\n",
      "375:\tlearn: 0.4147457\ttotal: 49m 47s\tremaining: 16m 25s\n",
      "376:\tlearn: 0.4147246\ttotal: 49m 56s\tremaining: 16m 17s\n",
      "377:\tlearn: 0.4147022\ttotal: 50m 5s\tremaining: 16m 9s\n",
      "378:\tlearn: 0.4146792\ttotal: 50m 14s\tremaining: 16m 2s\n",
      "379:\tlearn: 0.4146589\ttotal: 50m 22s\tremaining: 15m 54s\n",
      "380:\tlearn: 0.4146368\ttotal: 50m 29s\tremaining: 15m 46s\n",
      "381:\tlearn: 0.4146160\ttotal: 50m 38s\tremaining: 15m 38s\n",
      "382:\tlearn: 0.4145940\ttotal: 50m 48s\tremaining: 15m 31s\n",
      "383:\tlearn: 0.4145752\ttotal: 50m 58s\tremaining: 15m 23s\n",
      "384:\tlearn: 0.4145512\ttotal: 51m 7s\tremaining: 15m 16s\n",
      "385:\tlearn: 0.4145296\ttotal: 51m 14s\tremaining: 15m 8s\n",
      "386:\tlearn: 0.4145086\ttotal: 51m 22s\tremaining: 14m 59s\n",
      "387:\tlearn: 0.4144890\ttotal: 51m 30s\tremaining: 14m 52s\n",
      "388:\tlearn: 0.4144695\ttotal: 51m 39s\tremaining: 14m 44s\n",
      "389:\tlearn: 0.4144497\ttotal: 51m 49s\tremaining: 14m 37s\n",
      "390:\tlearn: 0.4144293\ttotal: 51m 56s\tremaining: 14m 28s\n",
      "391:\tlearn: 0.4144100\ttotal: 52m 6s\tremaining: 14m 21s\n",
      "392:\tlearn: 0.4143833\ttotal: 52m 14s\tremaining: 14m 13s\n",
      "393:\tlearn: 0.4143574\ttotal: 52m 26s\tremaining: 14m 6s\n",
      "394:\tlearn: 0.4143390\ttotal: 52m 34s\tremaining: 13m 58s\n",
      "395:\tlearn: 0.4143203\ttotal: 52m 43s\tremaining: 13m 50s\n",
      "396:\tlearn: 0.4143025\ttotal: 52m 50s\tremaining: 13m 42s\n",
      "397:\tlearn: 0.4142844\ttotal: 52m 58s\tremaining: 13m 34s\n",
      "398:\tlearn: 0.4142610\ttotal: 53m 8s\tremaining: 13m 27s\n",
      "399:\tlearn: 0.4142378\ttotal: 53m 16s\tremaining: 13m 19s\n",
      "400:\tlearn: 0.4142127\ttotal: 53m 25s\tremaining: 13m 11s\n",
      "401:\tlearn: 0.4141883\ttotal: 53m 33s\tremaining: 13m 3s\n",
      "402:\tlearn: 0.4141711\ttotal: 53m 41s\tremaining: 12m 55s\n",
      "403:\tlearn: 0.4141463\ttotal: 53m 49s\tremaining: 12m 47s\n",
      "404:\tlearn: 0.4141298\ttotal: 53m 57s\tremaining: 12m 39s\n",
      "405:\tlearn: 0.4141164\ttotal: 54m 6s\tremaining: 12m 31s\n",
      "406:\tlearn: 0.4140929\ttotal: 54m 13s\tremaining: 12m 23s\n",
      "407:\tlearn: 0.4140698\ttotal: 54m 22s\tremaining: 12m 15s\n",
      "408:\tlearn: 0.4140484\ttotal: 54m 30s\tremaining: 12m 7s\n",
      "409:\tlearn: 0.4140260\ttotal: 54m 38s\tremaining: 11m 59s\n",
      "410:\tlearn: 0.4140019\ttotal: 54m 48s\tremaining: 11m 52s\n",
      "411:\tlearn: 0.4139774\ttotal: 54m 59s\tremaining: 11m 44s\n",
      "412:\tlearn: 0.4139561\ttotal: 55m 8s\tremaining: 11m 36s\n",
      "413:\tlearn: 0.4139379\ttotal: 55m 16s\tremaining: 11m 28s\n",
      "414:\tlearn: 0.4139170\ttotal: 55m 27s\tremaining: 11m 21s\n",
      "415:\tlearn: 0.4139009\ttotal: 55m 35s\tremaining: 11m 13s\n",
      "416:\tlearn: 0.4138870\ttotal: 55m 44s\tremaining: 11m 5s\n",
      "417:\tlearn: 0.4138721\ttotal: 55m 55s\tremaining: 10m 58s\n",
      "418:\tlearn: 0.4138576\ttotal: 56m 4s\tremaining: 10m 50s\n",
      "419:\tlearn: 0.4138340\ttotal: 56m 17s\tremaining: 10m 43s\n",
      "420:\tlearn: 0.4138212\ttotal: 56m 26s\tremaining: 10m 35s\n",
      "421:\tlearn: 0.4138086\ttotal: 56m 35s\tremaining: 10m 27s\n",
      "422:\tlearn: 0.4137908\ttotal: 56m 43s\tremaining: 10m 19s\n",
      "423:\tlearn: 0.4137721\ttotal: 56m 53s\tremaining: 10m 11s\n",
      "424:\tlearn: 0.4137509\ttotal: 57m 2s\tremaining: 10m 3s\n",
      "425:\tlearn: 0.4137326\ttotal: 57m 11s\tremaining: 9m 56s\n",
      "426:\tlearn: 0.4137191\ttotal: 57m 21s\tremaining: 9m 48s\n",
      "427:\tlearn: 0.4137049\ttotal: 57m 31s\tremaining: 9m 40s\n",
      "428:\tlearn: 0.4136922\ttotal: 57m 40s\tremaining: 9m 32s\n",
      "429:\tlearn: 0.4136813\ttotal: 57m 52s\tremaining: 9m 25s\n",
      "430:\tlearn: 0.4136611\ttotal: 58m 2s\tremaining: 9m 17s\n",
      "431:\tlearn: 0.4136442\ttotal: 58m 11s\tremaining: 9m 9s\n",
      "432:\tlearn: 0.4136290\ttotal: 58m 23s\tremaining: 9m 2s\n",
      "433:\tlearn: 0.4136115\ttotal: 58m 33s\tremaining: 8m 54s\n",
      "434:\tlearn: 0.4135951\ttotal: 58m 43s\tremaining: 8m 46s\n",
      "435:\tlearn: 0.4135790\ttotal: 58m 51s\tremaining: 8m 38s\n",
      "436:\tlearn: 0.4135613\ttotal: 59m 1s\tremaining: 8m 30s\n",
      "437:\tlearn: 0.4135446\ttotal: 59m 7s\tremaining: 8m 22s\n",
      "438:\tlearn: 0.4135299\ttotal: 59m 16s\tremaining: 8m 14s\n",
      "439:\tlearn: 0.4135129\ttotal: 59m 26s\tremaining: 8m 6s\n",
      "440:\tlearn: 0.4134967\ttotal: 59m 35s\tremaining: 7m 58s\n",
      "441:\tlearn: 0.4134822\ttotal: 59m 45s\tremaining: 7m 50s\n",
      "442:\tlearn: 0.4134705\ttotal: 59m 57s\tremaining: 7m 42s\n",
      "443:\tlearn: 0.4134556\ttotal: 1h 7s\tremaining: 7m 34s\n",
      "444:\tlearn: 0.4134442\ttotal: 1h 16s\tremaining: 7m 26s\n",
      "445:\tlearn: 0.4134284\ttotal: 1h 27s\tremaining: 7m 19s\n",
      "446:\tlearn: 0.4134091\ttotal: 1h 35s\tremaining: 7m 11s\n",
      "447:\tlearn: 0.4133916\ttotal: 1h 45s\tremaining: 7m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448:\tlearn: 0.4133759\ttotal: 1h 55s\tremaining: 6m 55s\n",
      "449:\tlearn: 0.4133588\ttotal: 1h 1m 4s\tremaining: 6m 47s\n",
      "450:\tlearn: 0.4133422\ttotal: 1h 1m 15s\tremaining: 6m 39s\n",
      "451:\tlearn: 0.4133253\ttotal: 1h 1m 26s\tremaining: 6m 31s\n",
      "452:\tlearn: 0.4133069\ttotal: 1h 1m 38s\tremaining: 6m 23s\n",
      "453:\tlearn: 0.4132960\ttotal: 1h 1m 48s\tremaining: 6m 15s\n",
      "454:\tlearn: 0.4132794\ttotal: 1h 1m 56s\tremaining: 6m 7s\n",
      "455:\tlearn: 0.4132679\ttotal: 1h 2m 6s\tremaining: 5m 59s\n",
      "456:\tlearn: 0.4132515\ttotal: 1h 2m 17s\tremaining: 5m 51s\n",
      "457:\tlearn: 0.4132348\ttotal: 1h 2m 30s\tremaining: 5m 43s\n",
      "458:\tlearn: 0.4132241\ttotal: 1h 2m 40s\tremaining: 5m 35s\n",
      "459:\tlearn: 0.4132054\ttotal: 1h 2m 50s\tremaining: 5m 27s\n",
      "460:\tlearn: 0.4131892\ttotal: 1h 2m 59s\tremaining: 5m 19s\n",
      "461:\tlearn: 0.4131733\ttotal: 1h 3m 12s\tremaining: 5m 11s\n",
      "462:\tlearn: 0.4131574\ttotal: 1h 3m 23s\tremaining: 5m 3s\n",
      "463:\tlearn: 0.4131420\ttotal: 1h 3m 34s\tremaining: 4m 55s\n",
      "464:\tlearn: 0.4131261\ttotal: 1h 3m 44s\tremaining: 4m 47s\n",
      "465:\tlearn: 0.4131102\ttotal: 1h 3m 52s\tremaining: 4m 39s\n",
      "466:\tlearn: 0.4130950\ttotal: 1h 4m 3s\tremaining: 4m 31s\n",
      "467:\tlearn: 0.4130811\ttotal: 1h 4m 12s\tremaining: 4m 23s\n",
      "468:\tlearn: 0.4130673\ttotal: 1h 4m 21s\tremaining: 4m 15s\n",
      "469:\tlearn: 0.4130554\ttotal: 1h 4m 33s\tremaining: 4m 7s\n",
      "470:\tlearn: 0.4130428\ttotal: 1h 4m 44s\tremaining: 3m 59s\n",
      "471:\tlearn: 0.4130343\ttotal: 1h 4m 52s\tremaining: 3m 50s\n",
      "472:\tlearn: 0.4130172\ttotal: 1h 5m 1s\tremaining: 3m 42s\n",
      "473:\tlearn: 0.4130054\ttotal: 1h 5m 10s\tremaining: 3m 34s\n",
      "474:\tlearn: 0.4129941\ttotal: 1h 5m 30s\tremaining: 3m 26s\n",
      "475:\tlearn: 0.4129788\ttotal: 1h 5m 53s\tremaining: 3m 19s\n",
      "476:\tlearn: 0.4129658\ttotal: 1h 6m 4s\tremaining: 3m 11s\n",
      "477:\tlearn: 0.4129542\ttotal: 1h 6m 15s\tremaining: 3m 2s\n",
      "478:\tlearn: 0.4129421\ttotal: 1h 6m 25s\tremaining: 2m 54s\n",
      "479:\tlearn: 0.4129252\ttotal: 1h 6m 34s\tremaining: 2m 46s\n",
      "480:\tlearn: 0.4129114\ttotal: 1h 6m 44s\tremaining: 2m 38s\n",
      "481:\tlearn: 0.4129034\ttotal: 1h 6m 54s\tremaining: 2m 29s\n",
      "482:\tlearn: 0.4128923\ttotal: 1h 7m 5s\tremaining: 2m 21s\n",
      "483:\tlearn: 0.4128754\ttotal: 1h 7m 13s\tremaining: 2m 13s\n",
      "484:\tlearn: 0.4128600\ttotal: 1h 7m 23s\tremaining: 2m 5s\n",
      "485:\tlearn: 0.4128493\ttotal: 1h 7m 34s\tremaining: 1m 56s\n",
      "486:\tlearn: 0.4128342\ttotal: 1h 7m 43s\tremaining: 1m 48s\n",
      "487:\tlearn: 0.4128201\ttotal: 1h 7m 51s\tremaining: 1m 40s\n",
      "488:\tlearn: 0.4128123\ttotal: 1h 8m 1s\tremaining: 1m 31s\n",
      "489:\tlearn: 0.4128023\ttotal: 1h 8m 12s\tremaining: 1m 23s\n",
      "490:\tlearn: 0.4127878\ttotal: 1h 8m 20s\tremaining: 1m 15s\n",
      "491:\tlearn: 0.4127730\ttotal: 1h 8m 27s\tremaining: 1m 6s\n",
      "492:\tlearn: 0.4127623\ttotal: 1h 8m 37s\tremaining: 58.5s\n",
      "493:\tlearn: 0.4127515\ttotal: 1h 8m 47s\tremaining: 50.1s\n",
      "494:\tlearn: 0.4127422\ttotal: 1h 8m 55s\tremaining: 41.8s\n",
      "495:\tlearn: 0.4127316\ttotal: 1h 9m 6s\tremaining: 33.4s\n",
      "496:\tlearn: 0.4127132\ttotal: 1h 9m 14s\tremaining: 25.1s\n",
      "497:\tlearn: 0.4127044\ttotal: 1h 9m 24s\tremaining: 16.7s\n",
      "498:\tlearn: 0.4126954\ttotal: 1h 9m 33s\tremaining: 8.36s\n",
      "499:\tlearn: 0.4126876\ttotal: 1h 9m 41s\tremaining: 0us\n",
      "logloss of sj_test is: 0.46183\n"
     ]
    }
   ],
   "source": [
    "cat_sj = CatBoostClassifier(**best_p_c, od_type='Iter', eval_metric='Logloss')\n",
    "cat_sj.fit(df_copy, Y_train, cat_features=categorical_f, verbose=True)\n",
    "proba_ = cat_sj.predict_proba(df_sj.values)[:, 1]\n",
    "\n",
    "print('logloss of sj_test is: %0.5f'% log_loss(Y_test, proba_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6531283\ttotal: 566ms\tremaining: 56s\n",
      "1:\tlearn: 0.6203634\ttotal: 945ms\tremaining: 46.3s\n",
      "2:\tlearn: 0.5932915\ttotal: 1.55s\tremaining: 50.1s\n",
      "3:\tlearn: 0.5707390\ttotal: 1.92s\tremaining: 46.1s\n",
      "4:\tlearn: 0.5520063\ttotal: 2.31s\tremaining: 43.9s\n",
      "5:\tlearn: 0.5361472\ttotal: 2.68s\tremaining: 42s\n",
      "6:\tlearn: 0.5228734\ttotal: 3.05s\tremaining: 40.5s\n",
      "7:\tlearn: 0.5116808\ttotal: 3.43s\tremaining: 39.4s\n",
      "8:\tlearn: 0.5020503\ttotal: 3.88s\tremaining: 39.3s\n",
      "9:\tlearn: 0.4938029\ttotal: 4.28s\tremaining: 38.5s\n",
      "10:\tlearn: 0.4866742\ttotal: 4.72s\tremaining: 38.2s\n",
      "11:\tlearn: 0.4806740\ttotal: 5.2s\tremaining: 38.1s\n",
      "12:\tlearn: 0.4755052\ttotal: 5.66s\tremaining: 37.9s\n",
      "13:\tlearn: 0.4711380\ttotal: 6.14s\tremaining: 37.7s\n",
      "14:\tlearn: 0.4673230\ttotal: 6.54s\tremaining: 37.1s\n",
      "15:\tlearn: 0.4640916\ttotal: 6.93s\tremaining: 36.4s\n",
      "16:\tlearn: 0.4613016\ttotal: 7.32s\tremaining: 35.7s\n",
      "17:\tlearn: 0.4589544\ttotal: 7.68s\tremaining: 35s\n",
      "18:\tlearn: 0.4569079\ttotal: 8.04s\tremaining: 34.3s\n",
      "19:\tlearn: 0.4550533\ttotal: 8.41s\tremaining: 33.6s\n",
      "20:\tlearn: 0.4536096\ttotal: 8.77s\tremaining: 33s\n",
      "21:\tlearn: 0.4508569\ttotal: 9.2s\tremaining: 32.6s\n",
      "22:\tlearn: 0.4486046\ttotal: 9.57s\tremaining: 32s\n",
      "23:\tlearn: 0.4466435\ttotal: 9.94s\tremaining: 31.5s\n",
      "24:\tlearn: 0.4450335\ttotal: 10.3s\tremaining: 31s\n",
      "25:\tlearn: 0.4435478\ttotal: 10.7s\tremaining: 30.4s\n",
      "26:\tlearn: 0.4424288\ttotal: 11.1s\tremaining: 30s\n",
      "27:\tlearn: 0.4412762\ttotal: 11.5s\tremaining: 29.6s\n",
      "28:\tlearn: 0.4402142\ttotal: 11.9s\tremaining: 29.1s\n",
      "29:\tlearn: 0.4394011\ttotal: 12.3s\tremaining: 28.6s\n",
      "30:\tlearn: 0.4386955\ttotal: 12.6s\tremaining: 28.1s\n",
      "31:\tlearn: 0.4380606\ttotal: 13s\tremaining: 27.7s\n",
      "32:\tlearn: 0.4375830\ttotal: 13.4s\tremaining: 27.3s\n",
      "33:\tlearn: 0.4371646\ttotal: 13.8s\tremaining: 26.8s\n",
      "34:\tlearn: 0.4366739\ttotal: 14.2s\tremaining: 26.3s\n",
      "35:\tlearn: 0.4362739\ttotal: 14.5s\tremaining: 25.8s\n",
      "36:\tlearn: 0.4359141\ttotal: 14.9s\tremaining: 25.4s\n",
      "37:\tlearn: 0.4356321\ttotal: 15.3s\tremaining: 25s\n",
      "38:\tlearn: 0.4353830\ttotal: 15.7s\tremaining: 24.6s\n",
      "39:\tlearn: 0.4350517\ttotal: 16.1s\tremaining: 24.1s\n",
      "40:\tlearn: 0.4348509\ttotal: 16.5s\tremaining: 23.7s\n",
      "41:\tlearn: 0.4346039\ttotal: 16.9s\tremaining: 23.3s\n",
      "42:\tlearn: 0.4343799\ttotal: 17.2s\tremaining: 22.8s\n",
      "43:\tlearn: 0.4341972\ttotal: 17.6s\tremaining: 22.4s\n",
      "44:\tlearn: 0.4339731\ttotal: 18s\tremaining: 22s\n",
      "45:\tlearn: 0.4337676\ttotal: 18.4s\tremaining: 21.6s\n",
      "46:\tlearn: 0.4336349\ttotal: 18.8s\tremaining: 21.2s\n",
      "47:\tlearn: 0.4334523\ttotal: 19.2s\tremaining: 20.8s\n",
      "48:\tlearn: 0.4333451\ttotal: 19.6s\tremaining: 20.4s\n",
      "49:\tlearn: 0.4331840\ttotal: 20s\tremaining: 20s\n",
      "50:\tlearn: 0.4330606\ttotal: 20.4s\tremaining: 19.6s\n",
      "51:\tlearn: 0.4328488\ttotal: 20.8s\tremaining: 19.2s\n",
      "52:\tlearn: 0.4327362\ttotal: 21.2s\tremaining: 18.8s\n",
      "53:\tlearn: 0.4326009\ttotal: 21.6s\tremaining: 18.4s\n",
      "54:\tlearn: 0.4325295\ttotal: 22s\tremaining: 18s\n",
      "55:\tlearn: 0.4324348\ttotal: 22.5s\tremaining: 17.6s\n",
      "56:\tlearn: 0.4322988\ttotal: 22.8s\tremaining: 17.2s\n",
      "57:\tlearn: 0.4321716\ttotal: 23.3s\tremaining: 16.8s\n",
      "58:\tlearn: 0.4320800\ttotal: 23.7s\tremaining: 16.4s\n",
      "59:\tlearn: 0.4319882\ttotal: 24s\tremaining: 16s\n",
      "60:\tlearn: 0.4319093\ttotal: 24.4s\tremaining: 15.6s\n",
      "61:\tlearn: 0.4318156\ttotal: 24.8s\tremaining: 15.2s\n",
      "62:\tlearn: 0.4317339\ttotal: 25.2s\tremaining: 14.8s\n",
      "63:\tlearn: 0.4316729\ttotal: 25.6s\tremaining: 14.4s\n",
      "64:\tlearn: 0.4315789\ttotal: 26.1s\tremaining: 14s\n",
      "65:\tlearn: 0.4314980\ttotal: 26.5s\tremaining: 13.6s\n",
      "66:\tlearn: 0.4314402\ttotal: 26.9s\tremaining: 13.2s\n",
      "67:\tlearn: 0.4313738\ttotal: 27.3s\tremaining: 12.8s\n",
      "68:\tlearn: 0.4312810\ttotal: 27.7s\tremaining: 12.4s\n",
      "69:\tlearn: 0.4312019\ttotal: 28.1s\tremaining: 12s\n",
      "70:\tlearn: 0.4311321\ttotal: 28.5s\tremaining: 11.6s\n",
      "71:\tlearn: 0.4310839\ttotal: 28.9s\tremaining: 11.2s\n",
      "72:\tlearn: 0.4310136\ttotal: 29.3s\tremaining: 10.8s\n",
      "73:\tlearn: 0.4309720\ttotal: 29.7s\tremaining: 10.4s\n",
      "74:\tlearn: 0.4309274\ttotal: 30.2s\tremaining: 10.1s\n",
      "75:\tlearn: 0.4308836\ttotal: 30.5s\tremaining: 9.64s\n",
      "76:\tlearn: 0.4308581\ttotal: 31s\tremaining: 9.25s\n",
      "77:\tlearn: 0.4307853\ttotal: 31.4s\tremaining: 8.85s\n",
      "78:\tlearn: 0.4307166\ttotal: 31.8s\tremaining: 8.45s\n",
      "79:\tlearn: 0.4306651\ttotal: 32.2s\tremaining: 8.05s\n",
      "80:\tlearn: 0.4306188\ttotal: 32.6s\tremaining: 7.65s\n",
      "81:\tlearn: 0.4305880\ttotal: 33.1s\tremaining: 7.26s\n",
      "82:\tlearn: 0.4305506\ttotal: 33.5s\tremaining: 6.86s\n",
      "83:\tlearn: 0.4305165\ttotal: 33.9s\tremaining: 6.46s\n",
      "84:\tlearn: 0.4304974\ttotal: 34.4s\tremaining: 6.08s\n",
      "85:\tlearn: 0.4304630\ttotal: 34.9s\tremaining: 5.68s\n",
      "86:\tlearn: 0.4304003\ttotal: 35.4s\tremaining: 5.28s\n",
      "87:\tlearn: 0.4303469\ttotal: 35.8s\tremaining: 4.89s\n",
      "88:\tlearn: 0.4303082\ttotal: 36.3s\tremaining: 4.48s\n",
      "89:\tlearn: 0.4302580\ttotal: 36.7s\tremaining: 4.08s\n",
      "90:\tlearn: 0.4302300\ttotal: 37.1s\tremaining: 3.67s\n",
      "91:\tlearn: 0.4301928\ttotal: 37.5s\tremaining: 3.27s\n",
      "92:\tlearn: 0.4301693\ttotal: 38s\tremaining: 2.86s\n",
      "93:\tlearn: 0.4301320\ttotal: 38.5s\tremaining: 2.45s\n",
      "94:\tlearn: 0.4300989\ttotal: 38.9s\tremaining: 2.05s\n",
      "95:\tlearn: 0.4300622\ttotal: 39.3s\tremaining: 1.64s\n",
      "96:\tlearn: 0.4300114\ttotal: 39.7s\tremaining: 1.23s\n",
      "97:\tlearn: 0.4299937\ttotal: 40.2s\tremaining: 821ms\n",
      "98:\tlearn: 0.4299714\ttotal: 40.6s\tremaining: 410ms\n",
      "99:\tlearn: 0.4299499\ttotal: 41s\tremaining: 0us\n",
      "model logloss: 0.46583\n"
     ]
    }
   ],
   "source": [
    "cat_test = CatBoostClassifier(iterations=100,learning_rate=0.1,depth=7, eval_metric='Logloss')\n",
    "cat_test.fit(df_copy, Y_train, verbose=True, cat_features=categorical_f_2)\n",
    "y_pred_cat = cat_test.predict_proba(df_sj.values)[:, 1]\n",
    "print(\"model logloss: %.5f\" % log_loss(Y_test, y_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = convert_obj_to_int(df_copy)\n",
    "df_sj = convert_obj_to_int(df_sj)\n",
    "import lightgbm as lgb\n",
    "lgb_sj = lgb.LGBMClassifier(**best_p_l, loss_function='Logloss')\n",
    "lgb_sj.fit(df_copy, Y_train, verbose=True)\n",
    "proba_2 = lgb_sj.predict_proba(df_sj.values)[:, 1]\n",
    "\n",
    "print('logloss of sj_test is: %0.5f'% log_loss(Y_test, proba_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:27:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { bagging_temperature, border_count, depth, iterations, l2_leaf_reg, loss_function, random_strength } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:27:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prob1_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-258-64b9fad9cde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxgb_sj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mproba_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_sj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model logloss: %.5f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob1_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prob1_3' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "df_copy = convert_obj_to_int(df_copy)\n",
    "df_sj = convert_obj_to_int(df_sj)\n",
    "xgb_sj = XGBClassifier(**best_p_c, loss_function='Logloss')\n",
    "xgb_sj.fit(df_copy, Y_train, verbose=True)\n",
    "proba_3 = xgb_sj.predict_proba(df_sj.values)[:, 1]\n",
    "print(\"model logloss: %.5f\" % log_loss(Y_test, proba_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model logloss: 0.52193\n"
     ]
    }
   ],
   "source": [
    "print(\"model logloss: %.5f\" % log_loss(Y_test, proba_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model logloss: 0.45646\n"
     ]
    }
   ],
   "source": [
    "best_weight = [0.000999  , 0.000999  , 0.998002]\n",
    "proba_combined = proba_ * best_weight[0]+proba_3 * best_weight[1] +proba_2 * best_weight[2]\n",
    "print(\"model logloss: %.5f\" % log_loss(Y_test, proba_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_modified.gz\", compression='gzip', header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>...</th>\n",
       "      <th>device_id_count</th>\n",
       "      <th>hour_count</th>\n",
       "      <th>hourly_user_count</th>\n",
       "      <th>site_domain_int</th>\n",
       "      <th>site_category_int</th>\n",
       "      <th>device_id_int</th>\n",
       "      <th>device_ip_int</th>\n",
       "      <th>device_model_int</th>\n",
       "      <th>user_int</th>\n",
       "      <th>click_history_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21694</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>2075</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>167769</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7922621779461760780</td>\n",
       "      <td>-6768992271165658330</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>-3266082943187982762</td>\n",
       "      <td>-8936484730165669725</td>\n",
       "      <td>8369042709171464262</td>\n",
       "      <td>-1270970892774514273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16858</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>1465</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>167769</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8693261441984224658</td>\n",
       "      <td>3112977932537050345</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>-7631505241619422866</td>\n",
       "      <td>-3956929300217769292</td>\n",
       "      <td>3265855767023884082</td>\n",
       "      <td>-7818156423557073224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21759</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>2080</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>167769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-8688569517418306699</td>\n",
       "      <td>-4131573997570822417</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>-784420524355329646</td>\n",
       "      <td>3217593002617818802</td>\n",
       "      <td>-5556256507546026358</td>\n",
       "      <td>-8962407145868498340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19950</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>1378</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>167769</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-64485646154536219</td>\n",
       "      <td>3112977932537050345</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>-6344371719326813974</td>\n",
       "      <td>2169643850284159377</td>\n",
       "      <td>-3045071717250669269</td>\n",
       "      <td>7695420523787087916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19950</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>1378</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>167769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8089224346688236314</td>\n",
       "      <td>-5321392483428830522</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>8988571162419365100</td>\n",
       "      <td>-6038351737313936492</td>\n",
       "      <td>-5606010157720562442</td>\n",
       "      <td>-8962407145868498340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473605</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8330</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>339</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>324162</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1698749137548403830</td>\n",
       "      <td>-5321392483428830522</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>8988571162419365100</td>\n",
       "      <td>-6038351737313936492</td>\n",
       "      <td>5653339731379379104</td>\n",
       "      <td>-8962407145868498340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473606</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6616</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>154</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>324162</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4017769775047782938</td>\n",
       "      <td>3112977932537050345</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>-7838162323056977293</td>\n",
       "      <td>5436563076860855470</td>\n",
       "      <td>-3190853662056000661</td>\n",
       "      <td>-8962407145868498340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473607</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>2080</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>324162</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-8688569517418306699</td>\n",
       "      <td>-4131573997570822417</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>2413919770247425263</td>\n",
       "      <td>9222402813130808339</td>\n",
       "      <td>3437200189065378977</td>\n",
       "      <td>-8962407145868498340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473608</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15705</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>324162</td>\n",
       "      <td>270.0</td>\n",
       "      <td>-3903014210613918693</td>\n",
       "      <td>-5321392483428830522</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>8988571162419365100</td>\n",
       "      <td>-7506620169117425748</td>\n",
       "      <td>-3885195663964554779</td>\n",
       "      <td>-8962407145868498340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473609</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15706</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2974153</td>\n",
       "      <td>324162</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4000591738674953305</td>\n",
       "      <td>-5321392483428830522</td>\n",
       "      <td>630059432763922342</td>\n",
       "      <td>8988571162419365100</td>\n",
       "      <td>5682765318521204629</td>\n",
       "      <td>231654041431108129</td>\n",
       "      <td>-8962407145868498340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473610 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hour  C1  banner_pos  device_type  device_conn_type    C14  C15  C16  \\\n",
       "0          1   5           0            1                 0  21694  201   31   \n",
       "1          1   5           1            1                 0  16858  201   31   \n",
       "2          1   5           0            1                 0  21759  201   31   \n",
       "3          1   5           1            1                 0  19950  201   31   \n",
       "4          1   5           1            1                 0  19950  201   31   \n",
       "...      ...  ..         ...          ...               ...    ...  ...  ...   \n",
       "473605     5   5           0            1                 0   8330  201   31   \n",
       "473606     5   5           1            1                 0   6616  201   31   \n",
       "473607     5   5           0            1                 0  21763  201   31   \n",
       "473608     5   5           1            1                 0  15705  201   31   \n",
       "473609     5   5           0            1                 0  15706  201   31   \n",
       "\n",
       "         C17  C18  ...  device_id_count  hour_count  hourly_user_count  \\\n",
       "0       2075    3  ...          2974153      167769                3.0   \n",
       "1       1465    3  ...          2974153      167769                7.0   \n",
       "2       2080    0  ...          2974153      167769                2.0   \n",
       "3       1378    3  ...          2974153      167769               19.0   \n",
       "4       1378    3  ...          2974153      167769                1.0   \n",
       "...      ...  ...  ...              ...         ...                ...   \n",
       "473605   339    3  ...          2974153      324162                2.0   \n",
       "473606   154    2  ...          2974153      324162                7.0   \n",
       "473607  2080    0  ...          2974153      324162                2.0   \n",
       "473608  1300    0  ...          2974153      324162              270.0   \n",
       "473609  1300    0  ...          2974153      324162                2.0   \n",
       "\n",
       "            site_domain_int    site_category_int       device_id_int  \\\n",
       "0      -7922621779461760780 -6768992271165658330  630059432763922342   \n",
       "1      -8693261441984224658  3112977932537050345  630059432763922342   \n",
       "2      -8688569517418306699 -4131573997570822417  630059432763922342   \n",
       "3        -64485646154536219  3112977932537050345  630059432763922342   \n",
       "4       8089224346688236314 -5321392483428830522  630059432763922342   \n",
       "...                     ...                  ...                 ...   \n",
       "473605 -1698749137548403830 -5321392483428830522  630059432763922342   \n",
       "473606 -4017769775047782938  3112977932537050345  630059432763922342   \n",
       "473607 -8688569517418306699 -4131573997570822417  630059432763922342   \n",
       "473608 -3903014210613918693 -5321392483428830522  630059432763922342   \n",
       "473609 -4000591738674953305 -5321392483428830522  630059432763922342   \n",
       "\n",
       "              device_ip_int     device_model_int             user_int  \\\n",
       "0      -3266082943187982762 -8936484730165669725  8369042709171464262   \n",
       "1      -7631505241619422866 -3956929300217769292  3265855767023884082   \n",
       "2       -784420524355329646  3217593002617818802 -5556256507546026358   \n",
       "3      -6344371719326813974  2169643850284159377 -3045071717250669269   \n",
       "4       8988571162419365100 -6038351737313936492 -5606010157720562442   \n",
       "...                     ...                  ...                  ...   \n",
       "473605  8988571162419365100 -6038351737313936492  5653339731379379104   \n",
       "473606 -7838162323056977293  5436563076860855470 -3190853662056000661   \n",
       "473607  2413919770247425263  9222402813130808339  3437200189065378977   \n",
       "473608  8988571162419365100 -7506620169117425748 -3885195663964554779   \n",
       "473609  8988571162419365100  5682765318521204629   231654041431108129   \n",
       "\n",
       "          click_history_int  \n",
       "0      -1270970892774514273  \n",
       "1      -7818156423557073224  \n",
       "2      -8962407145868498340  \n",
       "3       7695420523787087916  \n",
       "4      -8962407145868498340  \n",
       "...                     ...  \n",
       "473605 -8962407145868498340  \n",
       "473606 -8962407145868498340  \n",
       "473607 -8962407145868498340  \n",
       "473608 -8962407145868498340  \n",
       "473609 -8962407145868498340  \n",
       "\n",
       "[473610 rows x 25 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_cols_2 = ['site_id', 'user', 'click_history', 'day_of_week', 'device_ip_count', 'hour_count', \n",
    "                 'hourly_user_count']\n",
    "unused_cols = ['site_id']\n",
    "df_test.drop(unused_cols, axis=1, inplace=True)\n",
    "categorical_f_2 = ['C1', 'banner_pos','site_domain','site_category','device_id','device_ip','device_model',\n",
    "                 'device_type','device_conn_type', 'C14','C15','C16','C17','C18', 'C19','C20','C21',\n",
    "                     ]\n",
    "categorical_f = ['C1', 'banner_pos','site_domain','site_category','device_id','device_ip','device_model',\n",
    "                 'device_type','device_conn_type', 'C14','C15','C16','C17','C18', 'C19','C20','C21',\n",
    "                 'day_of_week', 'user', 'click_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_1t = cat_sj.predict_proba(df_test.values)[:, 1]\n",
    "df_test = convert_obj_to_int(df_test)\n",
    "proba_2t = lgb_sj.predict_proba(df_test.values)[:, 1]\n",
    "proba_3t = xgb_sj.predict_proba(df_test.values)[:, 1]\n",
    "best_weight = [0.000999  , 0.000999  , 0.998002]\n",
    "proba_combined_t = proba_1t * best_weight[0]+proba_3t * best_weight[1] +proba_2t * best_weight[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00400319, 0.02942782, 0.236705  , ..., 0.3060573 , 0.10958013,\n",
       "       0.07735443])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_combined_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prep = pd.read_csv(\"test.gz\", compression='gzip', header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id = df_test_prep['id']\n",
    "df_out = pd.DataFrame({'id': all_id, 'ctr': proba_combined_t})\n",
    "df_out.to_csv('Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p_l = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 5, \n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.11304216699488043,\n",
    "    'feature_fraction': 0.5066204305086464,\n",
    "    'bagging_fraction': 0.6657456066570288,\n",
    "    'max_bin': 188,\n",
    "    'n_estimators': 482,\n",
    "    'num_leaves': 60,\n",
    "    'min_sum_hessian_in_leaf':72\n",
    "}\n",
    "\n",
    "best_p_l_1 = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 2, \n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.037681961372348104,\n",
    "    'feature_fraction': 0.6186329542584896,\n",
    "    'bagging_fraction': 0.7686771918501543,\n",
    "    'max_bin': 198,\n",
    "    'n_estimators': 854,\n",
    "    'num_leaves': 58,\n",
    "    'min_sum_hessian_in_leaf':34,\n",
    "    'lambda_l1': 8.027647813535458,\n",
    "    'lambda_l2': 5.230523285313312,\n",
    "    'min_data_in_leaf': 93,\n",
    "    'min_split_gain': 0.03929273115755069\n",
    "}\n",
    "\n",
    "best_p_l_2 = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 7, \n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.3,\n",
    "    'feature_fraction': 0.8999999999999999,\n",
    "    'bagging_fraction': 0.8999999999999999,\n",
    "    'max_bin': 59,\n",
    "    'n_estimators': 218,\n",
    "    'num_leaves': 80,\n",
    "    'min_sum_hessian_in_leaf':0,\n",
    "    'lambda_l1': 1e-08,\n",
    "    'lambda_l2': 3.3855221440653636,\n",
    "    'min_data_in_leaf':26,\n",
    "    'min_split_gain': 0.03132393135883699\n",
    "}\n",
    "\n",
    "best_p_c = {\n",
    "    'iterations': 300,\n",
    "    'depth': 8,\n",
    "    'l2_leaf_reg': 30,\n",
    "    'random_strength': 9.725165337630147,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'bagging_temperature':1.0,\n",
    "    'border_count':1.0,\n",
    "    'learning_rate': 0.23151807420324574\n",
    "}\n",
    "\n",
    "best_p_c1 = {\n",
    "    'colsample_bylevel':1.0,\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 1000,\n",
    "    'leaf_estimation_iterations': 5\n",
    "    'model_size_reg': 0.001\n",
    "    'random_strength': 10.0,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'subsample':1.0\n",
    "}\n",
    "\n",
    "best_p_c2 = {\n",
    "    'colsample_bylevel':0.6,\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 1000,\n",
    "    'leaf_estimation_iterations': 1\n",
    "    'model_size_reg': 0.001\n",
    "    'random_strength': 1e-09,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'subsample':0.6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "final_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

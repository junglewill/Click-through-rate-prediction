{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_modified.gz\", compression=\"gzip\")\n",
    "test = pd.read_csv(\"test_modified.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hash = df.copy()\n",
    "def convert_obj_to_int(self):\n",
    "    object_list_columns = self.columns\n",
    "    object_list_dtypes = self.dtypes\n",
    "    new_col_suffix = '_int'\n",
    "    for index in range(0,len(object_list_columns)):\n",
    "        if object_list_dtypes[index] == object :\n",
    "            self[object_list_columns[index]+new_col_suffix] = self[object_list_columns[index]].map( lambda  x: hash(x))\n",
    "            self.drop([object_list_columns[index]],inplace=True,axis=1)\n",
    "    return self\n",
    "\n",
    "LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "df_hash = convert_obj_to_int(df_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hash = test.copy()\n",
    "test_hash = convert_obj_to_int(test_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal hyperparameters\n",
    "best_p_l = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 5, \n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.11304216699488043,\n",
    "    'feature_fraction': 0.5066204305086464,\n",
    "    'bagging_fraction': 0.6657456066570288,\n",
    "    'max_bin': 188,\n",
    "    'n_estimators': 482,\n",
    "    'num_leaves': 60,\n",
    "    'min_sum_hessian_in_leaf':72\n",
    "}\n",
    "\n",
    "best_p_l_8 = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 2, \n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.037681961372348104,\n",
    "    'feature_fraction': 0.6186329542584896,\n",
    "    'bagging_fraction': 0.7686771918501543,\n",
    "    'max_bin': 198,\n",
    "    'n_estimators': 854,\n",
    "    'num_leaves': 58,\n",
    "    'min_sum_hessian_in_leaf':34,\n",
    "    'lambda_l1': 8.027647813535458,\n",
    "    'lambda_l2': 5.230523285313312,\n",
    "    'min_data_in_leaf': 93,\n",
    "    'min_split_gain': 0.03929273115755069\n",
    "}\n",
    "\n",
    "best_p_l_28 = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 7, \n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.3,\n",
    "    'feature_fraction': 0.8999999999999999,\n",
    "    'bagging_fraction': 0.8999999999999999,\n",
    "    'max_bin': 59,\n",
    "    'n_estimators': 218,\n",
    "    'num_leaves': 80,\n",
    "    'min_sum_hessian_in_leaf':0,\n",
    "    'lambda_l1': 1e-08,\n",
    "    'lambda_l2': 3.3855221440653636,\n",
    "    'min_data_in_leaf':26,\n",
    "    'min_split_gain': 0.03132393135883699\n",
    "}\n",
    "\n",
    "best_p_l_4812 = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 1, \n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.17830921881011944,\n",
    "    'feature_fraction': 0.5866476844693964,\n",
    "    'bagging_fraction': 0.8331767682764499,\n",
    "    'max_bin': 255,\n",
    "    'n_estimators': 283,\n",
    "    'num_leaves': 24,\n",
    "    'min_sum_hessian_in_leaf':4,\n",
    "    'lambda_l1': 4.227555053091508,\n",
    "    'lambda_l2': 3.7698218608912613,\n",
    "    'min_data_in_leaf':65,\n",
    "    'min_split_gain': 0.024848679158260303\n",
    "}\n",
    "\n",
    "best_p_l_19 = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 7, \n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.3,\n",
    "    'feature_fraction': 0.8999999999999999,\n",
    "    'bagging_fraction': 0.8999999999999999,\n",
    "    'max_bin': 255,\n",
    "    'n_estimators': 1000,\n",
    "    'num_leaves': 80,\n",
    "    'min_sum_hessian_in_leaf':0,\n",
    "    'lambda_l1': 10.0,\n",
    "    'lambda_l2': 1e-08,\n",
    "    'min_data_in_leaf':20,\n",
    "    'min_split_gain': 0.1\n",
    "}\n",
    "\n",
    "best_p_l_48128 = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric':'binary_logloss', \n",
    "    'bagging_freq': 1, \n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.29287582078739416,\n",
    "    'feature_fraction': 0.8999999999999999,\n",
    "    'bagging_fraction': 0.8999999999999999,\n",
    "    'max_bin': 255,\n",
    "    'n_estimators': 625,\n",
    "    'num_leaves': 80,\n",
    "    'min_sum_hessian_in_leaf':0,\n",
    "    'lambda_l1': 10.0,\n",
    "    'lambda_l2': 1e-08,\n",
    "    'min_data_in_leaf':20,\n",
    "    'min_split_gain': 0.001\n",
    "}\n",
    "\n",
    "best_p_x = {\n",
    "    'alpha':0.0,\n",
    "    'colsample_bytree':1.0,\n",
    "    'gamma':0.0,\n",
    "    'iterations':400,\n",
    "    'learning_rate':0.27950642975302614,\n",
    "    'max_depth':5,\n",
    "    'n_estimators':100,\n",
    "    'subsample':1.0\n",
    "}\n",
    "\n",
    "best_p_c_2 = {\n",
    "    'colsample_bylevel':1.0,\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 1000,\n",
    "    'leaf_estimation_iterations': 5,\n",
    "    'model_size_reg': 0.001,\n",
    "    'random_strength': 10.0,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'subsample':1.0\n",
    "}\n",
    "\n",
    "best_p_c_240 = {\n",
    "    'colsample_bylevel':0.6,\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 1000,\n",
    "    'leaf_estimation_iterations': 1,\n",
    "    'model_size_reg': 0.001,\n",
    "    'random_strength': 1e-09,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'subsample':0.6\n",
    "}\n",
    "\n",
    "best_p_c_101 = {\n",
    "    'colsample_bylevel':0.5,\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 0.001,\n",
    "    'leaf_estimation_iterations': 1,\n",
    "    'model_size_reg': 0.01,\n",
    "    'random_strength': 10,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'subsample':1.0\n",
    "}\n",
    "\n",
    "best_p_c_16 = {\n",
    "    'colsample_bylevel':1.0,\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 10000.0,\n",
    "    'leaf_estimation_iterations': 1,\n",
    "    'model_size_reg': 0.01,\n",
    "    'random_strength': 1e-9,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'subsample':1.0\n",
    "}\n",
    "\n",
    "best_p_c_24 = {\n",
    "    'colsample_bylevel':1.0,\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 0.001,\n",
    "    'leaf_estimation_iterations': 5,\n",
    "    'model_size_reg': 0.01,\n",
    "    'random_strength': 1e-9,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'subsample':1.0\n",
    "}\n",
    "\n",
    "best_p_c_93 = {\n",
    "    'colsample_bylevel':0.8632239657609391,\n",
    "    'iterations': 253,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 0.04950136398986362,\n",
    "    'random_strength': 8.859981483391271,\n",
    "    'scale_pos_weight':4.0,\n",
    "    'subsample':0.8656939072041325\n",
    "}\n",
    "\n",
    "best_p_c_94 = {\n",
    "    'colsample_bylevel':0.5543980525240869,\n",
    "    'iterations': 229,\n",
    "    'depth': 4,\n",
    "    'l2_leaf_reg': 0.0014643709007568422,\n",
    "    'random_strength': 7.3571198753222635,\n",
    "    'scale_pos_weight':4.0,\n",
    "    'subsample':0.9404022748170857\n",
    "}\n",
    "\n",
    "best_p_c_95 = {\n",
    "    'colsample_bylevel':0.6734806370500523,\n",
    "    'iterations': 292,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg':0.007633206168459772,\n",
    "    'random_strength': 6.779441783613398,\n",
    "    'scale_pos_weight':4.0,\n",
    "    'subsample':0.5860249353681423\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.6657456066570288, bagging_freq=5,\n",
       "               feature_fraction=0.5066204305086464,\n",
       "               learning_rate=0.11304216699488043, loss_function='Logloss',\n",
       "               max_bin=188, max_depth=7, metric='binary_logloss',\n",
       "               min_sum_hessian_in_leaf=72, n_estimators=482, num_leaves=60,\n",
       "               objective='binary')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightgbm\n",
    "X_train = df_hash.drop([\"click\"], axis=1)\n",
    "y_train = df_hash[\"click\"]\n",
    "lgb0 = lgb.LGBMClassifier(**best_p_l, loss_function='Logloss')\n",
    "lgb0.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.7686771918501543, bagging_freq=2,\n",
       "               feature_fraction=0.6186329542584896, lambda_l1=8.027647813535458,\n",
       "               lambda_l2=5.230523285313312, learning_rate=0.037681961372348104,\n",
       "               loss_function='Logloss', max_bin=198, max_depth=9,\n",
       "               metric='binary_logloss', min_data_in_leaf=93,\n",
       "               min_split_gain=0.03929273115755069, min_sum_hessian_in_leaf=34,\n",
       "               n_estimators=854, num_leaves=58, objective='binary')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightgbm 8\n",
    "df_bootstrapped = df_hash.sample(n=len(df_hash), replace=True, random_state=8)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "lgb8 = lgb.LGBMClassifier(**best_p_l_8, loss_function='Logloss')\n",
    "lgb8.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8999999999999999, bagging_freq=7,\n",
       "               feature_fraction=0.8999999999999999, lambda_l1=1e-08,\n",
       "               lambda_l2=3.3855221440653636, learning_rate=0.3,\n",
       "               loss_function='Logloss', max_bin=59, max_depth=10,\n",
       "               metric='binary_logloss', min_data_in_leaf=26,\n",
       "               min_split_gain=0.03132393135883699, min_sum_hessian_in_leaf=0,\n",
       "               n_estimators=218, num_leaves=80, objective='binary')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightgbm 28\n",
    "df_bootstrapped = df_hash.sample(n=len(df_hash), replace=True, random_state=28)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "lgb28 = lgb.LGBMClassifier(**best_p_l_28, loss_function='Logloss')\n",
    "lgb28.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5866476844693964, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5866476844693964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.227555053091508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.227555053091508\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8331767682764499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8331767682764499\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7698218608912613, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.7698218608912613\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8331767682764499, bagging_freq=1,\n",
       "               feature_fraction=0.5866476844693964, lambda_l1=4.227555053091508,\n",
       "               lambda_l2=3.7698218608912613, learning_rate=0.17830921881011944,\n",
       "               loss_function='Logloss', max_bin=255, max_depth=4,\n",
       "               metric='binary_logloss', min_data_in_leaf=65,\n",
       "               min_split_gain=0.024848679158260303, min_sum_hessian_in_leaf=4,\n",
       "               n_estimators=283, num_leaves=24, objective='binary')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightgbm 4812\n",
    "df_bootstrapped = df_hash.sample(n=len(df_hash), replace=True, random_state=4812)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "lgb4812 = lgb.LGBMClassifier(**best_p_l_4812, loss_function='Logloss')\n",
    "lgb4812.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8999999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8999999999999999\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=10.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8999999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8999999999999999\n",
      "[LightGBM] [Warning] lambda_l2 is set=1e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8999999999999999, bagging_freq=7,\n",
       "               feature_fraction=0.8999999999999999, lambda_l1=10.0,\n",
       "               lambda_l2=1e-08, learning_rate=0.3, loss_function='Logloss',\n",
       "               max_bin=255, max_depth=10, metric='binary_logloss',\n",
       "               min_data_in_leaf=20, min_split_gain=0.1,\n",
       "               min_sum_hessian_in_leaf=0, n_estimators=1000, num_leaves=80,\n",
       "               objective='binary')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightgbm 19\n",
    "df_bootstrapped = df_hash.sample(n=len(df_hash), replace=True, random_state=19)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "lgb19 = lgb.LGBMClassifier(**best_p_l_19, loss_function='Logloss')\n",
    "lgb19.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: loss_function\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8999999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8999999999999999\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=10.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8999999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8999999999999999\n",
      "[LightGBM] [Warning] lambda_l2 is set=1e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8999999999999999, bagging_freq=1,\n",
       "               feature_fraction=0.8999999999999999, lambda_l1=10.0,\n",
       "               lambda_l2=1e-08, learning_rate=0.29287582078739416,\n",
       "               loss_function='Logloss', max_bin=255, max_depth=10,\n",
       "               metric='binary_logloss', min_data_in_leaf=20,\n",
       "               min_split_gain=0.001, min_sum_hessian_in_leaf=0,\n",
       "               n_estimators=625, num_leaves=80, objective='binary')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightgbm 48128\n",
    "df_bootstrapped = df_hash.sample(n=len(df_hash), replace=True, random_state=48128)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "lgb48128 = lgb.LGBMClassifier(**best_p_l_48128, loss_function='Logloss')\n",
    "lgb48128.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:56:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { iterations, loss_function } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:56:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.0, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0, gamma=0.0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              iterations=400, learning_rate=0.27950642975302614,\n",
       "              loss_function='Logloss', max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost\n",
    "X_train = df_hash.drop([\"click\"], axis=1)\n",
    "y_train = df_hash[\"click\"]\n",
    "xgb0 = XGBClassifier(**best_p_x, loss_function='Logloss')\n",
    "xgb0.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,:21] = df.iloc[:,:21].astype(\"category\")\n",
    "df.iloc[:,24] = df.iloc[:,24].astype(\"category\")\n",
    "df.iloc[:,26] = df.iloc[:,26].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_f = ['hour', 'C1', 'banner_pos', 'site_id', 'site_domain','site_category','device_id','device_ip','device_model',\n",
    "                 'device_type','device_conn_type', 'C14','C15','C16','C17','C18', 'C19','C20','C21',\n",
    "                 'day_of_week', 'user', 'click_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost 2\n",
    "df_bootstrapped = df.sample(n=len(df), replace=True, random_state=2)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "catboost2 = CatBoostClassifier(**best_p_c_2, cat_features=categorical_f, loss_function='Logloss')\n",
    "catboost2.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost 240\n",
    "df_bootstrapped = df.sample(n=len(df), replace=True, random_state=240)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "catboost240 = CatBoostClassifier(**best_p_c_240, cat_features=categorical_f, loss_function='Logloss')\n",
    "catboost240.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost 101\n",
    "df_bootstrapped = df.sample(n=len(df), replace=True, random_state=101)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "catboost101 = CatBoostClassifier(**best_p_c_101, cat_features=categorical_f, loss_function='Logloss')\n",
    "catboost101.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost 16\n",
    "df_bootstrapped = df.sample(n=len(df), replace=True, random_state=16)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "catboost16 = CatBoostClassifier(**best_p_c_16, cat_features=categorical_f, loss_function='Logloss')\n",
    "catboost16.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost 24\n",
    "df_bootstrapped = df.sample(n=len(df), replace=True, random_state=24)\n",
    "X_train = df_bootstrapped.drop([\"click\"], axis=1)\n",
    "y_train = df_bootstrapped[\"click\"]\n",
    "catboost24 = CatBoostClassifier(**best_p_c_24, cat_features=categorical_f, loss_function='Logloss')\n",
    "catboost24.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb0_pred = lgb0.predict_proba(test_hash)[:,1]\n",
    "lgb8_pred = lgb8.predict_proba(test_hash)[:,1]\n",
    "lgb28_pred = lgb28.predict_proba(test_hash)[:,1]\n",
    "lgb4812_pred = lgb4812.predict_proba(test_hash)[:,1]\n",
    "lgb19_pred = lgb19.predict_proba(test_hash)[:,1]\n",
    "lgb48128_pred = lgb48128.predict_proba(test_hash)[:,1]\n",
    "xgb0_pred = xgb0.predict_proba(test_hash)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id = pd.read_csv(\"test.gz\", compression=\"gzip\", usecols=[\"id\"])\n",
    "catboost95_pred = pd.read_csv(\"catboost95_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame({'id': id[\"id\"].values, 'lgb0': lgb0_pred, 'lgb8': lgb8_pred, 'lgb28': lgb28_pred, 'xgb0': xgb0_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(\"pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.read_csv(\"pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.insert(6, \"lgb48128\", lgb48128_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_logistic(x):\n",
    "    return np.log((x/(1-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_average(row):\n",
    "    proba = row[1:12]\n",
    "    logistic_sum = 0\n",
    "    for prob in proba:\n",
    "        logistic_sum += inverse_logistic(prob)\n",
    "    average = logistic_sum/len(proba)\n",
    "    return expit(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_average(row):\n",
    "    mean = row[1:12].mean()\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_weights = [0.25,0.25,0.25,0.025,0.025,0.025,0.025,0.025,0.125]\n",
    "def weighted_average(row):\n",
    "    return sum(row[1:10]*opt_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[\"logistic_avg\"] = df_out.apply(lambda row: logistic_average(row), axis=1)\n",
    "df_out[\"simple_avg\"] = df_out.apply(lambda row: simple_average(row), axis=1)\n",
    "#df_out[\"weighted_avg\"] = df_out.apply(lambda row: weighted_average(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lgb0</th>\n",
       "      <th>lgb8</th>\n",
       "      <th>lgb28</th>\n",
       "      <th>lgb4812</th>\n",
       "      <th>lgb19</th>\n",
       "      <th>lgb48128</th>\n",
       "      <th>xgb0</th>\n",
       "      <th>catboost2</th>\n",
       "      <th>catboost240</th>\n",
       "      <th>catboost101</th>\n",
       "      <th>catboost16</th>\n",
       "      <th>catboost24</th>\n",
       "      <th>logistic_avg</th>\n",
       "      <th>simple_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2683788</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>0.022848</td>\n",
       "      <td>0.039103</td>\n",
       "      <td>0.012432</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2683789</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.028873</td>\n",
       "      <td>0.022988</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.027275</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.017472</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.039405</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>0.021728</td>\n",
       "      <td>0.022907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2683790</td>\n",
       "      <td>0.255547</td>\n",
       "      <td>0.275426</td>\n",
       "      <td>0.296484</td>\n",
       "      <td>0.272314</td>\n",
       "      <td>0.359044</td>\n",
       "      <td>0.225064</td>\n",
       "      <td>0.264054</td>\n",
       "      <td>0.269433</td>\n",
       "      <td>0.268108</td>\n",
       "      <td>0.268974</td>\n",
       "      <td>0.265767</td>\n",
       "      <td>0.272090</td>\n",
       "      <td>0.278157</td>\n",
       "      <td>0.278840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2683791</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.035248</td>\n",
       "      <td>0.043614</td>\n",
       "      <td>0.034865</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.023455</td>\n",
       "      <td>0.022735</td>\n",
       "      <td>0.026592</td>\n",
       "      <td>0.044561</td>\n",
       "      <td>0.021117</td>\n",
       "      <td>0.027131</td>\n",
       "      <td>0.028529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2683792</td>\n",
       "      <td>0.145924</td>\n",
       "      <td>0.146929</td>\n",
       "      <td>0.163117</td>\n",
       "      <td>0.143680</td>\n",
       "      <td>0.125987</td>\n",
       "      <td>0.128779</td>\n",
       "      <td>0.135061</td>\n",
       "      <td>0.141528</td>\n",
       "      <td>0.125722</td>\n",
       "      <td>0.138139</td>\n",
       "      <td>0.137201</td>\n",
       "      <td>0.152182</td>\n",
       "      <td>0.141088</td>\n",
       "      <td>0.141407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473605</th>\n",
       "      <td>3157393</td>\n",
       "      <td>0.166628</td>\n",
       "      <td>0.132019</td>\n",
       "      <td>0.101980</td>\n",
       "      <td>0.165562</td>\n",
       "      <td>0.119291</td>\n",
       "      <td>0.042183</td>\n",
       "      <td>0.154899</td>\n",
       "      <td>0.119563</td>\n",
       "      <td>0.114990</td>\n",
       "      <td>0.115694</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.135779</td>\n",
       "      <td>0.130040</td>\n",
       "      <td>0.131390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473606</th>\n",
       "      <td>3157394</td>\n",
       "      <td>0.229093</td>\n",
       "      <td>0.238537</td>\n",
       "      <td>0.174584</td>\n",
       "      <td>0.230970</td>\n",
       "      <td>0.154269</td>\n",
       "      <td>0.191631</td>\n",
       "      <td>0.237094</td>\n",
       "      <td>0.225183</td>\n",
       "      <td>0.230766</td>\n",
       "      <td>0.239067</td>\n",
       "      <td>0.226265</td>\n",
       "      <td>0.196092</td>\n",
       "      <td>0.215106</td>\n",
       "      <td>0.216538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473607</th>\n",
       "      <td>3157395</td>\n",
       "      <td>0.346887</td>\n",
       "      <td>0.355721</td>\n",
       "      <td>0.336584</td>\n",
       "      <td>0.352246</td>\n",
       "      <td>0.477560</td>\n",
       "      <td>0.346163</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>0.301159</td>\n",
       "      <td>0.312619</td>\n",
       "      <td>0.283442</td>\n",
       "      <td>0.272942</td>\n",
       "      <td>0.308131</td>\n",
       "      <td>0.332002</td>\n",
       "      <td>0.333653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473608</th>\n",
       "      <td>3157396</td>\n",
       "      <td>0.140113</td>\n",
       "      <td>0.171246</td>\n",
       "      <td>0.103311</td>\n",
       "      <td>0.179477</td>\n",
       "      <td>0.170272</td>\n",
       "      <td>0.121132</td>\n",
       "      <td>0.184785</td>\n",
       "      <td>0.212750</td>\n",
       "      <td>0.156941</td>\n",
       "      <td>0.217162</td>\n",
       "      <td>0.213525</td>\n",
       "      <td>0.081133</td>\n",
       "      <td>0.161198</td>\n",
       "      <td>0.166429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473609</th>\n",
       "      <td>3157397</td>\n",
       "      <td>0.098247</td>\n",
       "      <td>0.089081</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.104256</td>\n",
       "      <td>0.070858</td>\n",
       "      <td>0.036681</td>\n",
       "      <td>0.138738</td>\n",
       "      <td>0.070124</td>\n",
       "      <td>0.081117</td>\n",
       "      <td>0.082751</td>\n",
       "      <td>0.110925</td>\n",
       "      <td>0.070133</td>\n",
       "      <td>0.087314</td>\n",
       "      <td>0.089348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473610 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id      lgb0      lgb8     lgb28   lgb4812     lgb19  lgb48128  \\\n",
       "0       2683788  0.006452  0.006541  0.007520  0.007663  0.007946  0.005476   \n",
       "1       2683789  0.021002  0.028873  0.022988  0.031505  0.014868  0.021610   \n",
       "2       2683790  0.255547  0.275426  0.296484  0.272314  0.359044  0.225064   \n",
       "3       2683791  0.019650  0.035248  0.043614  0.034865  0.015509  0.013981   \n",
       "4       2683792  0.145924  0.146929  0.163117  0.143680  0.125987  0.128779   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "473605  3157393  0.166628  0.132019  0.101980  0.165562  0.119291  0.042183   \n",
       "473606  3157394  0.229093  0.238537  0.174584  0.230970  0.154269  0.191631   \n",
       "473607  3157395  0.346887  0.355721  0.336584  0.352246  0.477560  0.346163   \n",
       "473608  3157396  0.140113  0.171246  0.103311  0.179477  0.170272  0.121132   \n",
       "473609  3157397  0.098247  0.089081  0.066600  0.104256  0.070858  0.036681   \n",
       "\n",
       "            xgb0  catboost2  catboost240  catboost101  catboost16  catboost24  \\\n",
       "0       0.009805   0.012173     0.019374     0.022848    0.039103    0.012432   \n",
       "1       0.027275   0.016344     0.017472     0.019128    0.039405    0.013116   \n",
       "2       0.264054   0.269433     0.268108     0.268974    0.265767    0.272090   \n",
       "3       0.026471   0.023455     0.022735     0.026592    0.044561    0.021117   \n",
       "4       0.135061   0.141528     0.125722     0.138139    0.137201    0.152182   \n",
       "...          ...        ...          ...          ...         ...         ...   \n",
       "473605  0.154899   0.119563     0.114990     0.115694    0.118881    0.135779   \n",
       "473606  0.237094   0.225183     0.230766     0.239067    0.226265    0.196092   \n",
       "473607  0.322887   0.301159     0.312619     0.283442    0.272942    0.308131   \n",
       "473608  0.184785   0.212750     0.156941     0.217162    0.213525    0.081133   \n",
       "473609  0.138738   0.070124     0.081117     0.082751    0.110925    0.070133   \n",
       "\n",
       "        logistic_avg  simple_avg  \n",
       "0           0.011594    0.013805  \n",
       "1           0.021728    0.022907  \n",
       "2           0.278157    0.278840  \n",
       "3           0.027131    0.028529  \n",
       "4           0.141088    0.141407  \n",
       "...              ...         ...  \n",
       "473605      0.130040    0.131390  \n",
       "473606      0.215106    0.216538  \n",
       "473607      0.332002    0.333653  \n",
       "473608      0.161198    0.166429  \n",
       "473609      0.087314    0.089348  \n",
       "\n",
       "[473610 rows x 15 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_out = df_out.iloc[:,[0,5,6,7,8,9]]\n",
    "catboost_out[\"logistic_avg\"] = df_out.apply(lambda row: logistic_average(row), axis=1)\n",
    "catboost_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_out[[\"id\", \"weighted_avg\"]]\n",
    "submission.rename(columns={\"weighted_avg\": \"ctr\"}).to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.gz\")\n",
    "sj_test = pd.read_csv('sj_test.gz')\n",
    "\n",
    "X_train = train_df.drop([\"click\"],axis=1)\n",
    "y_train = train_df[\"click\"]\n",
    "\n",
    "column_list = ['C1', 'banner_pos', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', \n",
    "               'C19', 'C20', 'C21']\n",
    "X_train[column_list] = X_train[column_list].astype('object')\n",
    "\n",
    "def convert_obj_to_int(self):\n",
    "    object_list_columns = self.columns\n",
    "    object_list_dtypes = self.dtypes\n",
    "    new_col_suffix = '_int'\n",
    "    for index in range(0,len(object_list_columns)):\n",
    "        if object_list_dtypes[index] == object :\n",
    "            self[object_list_columns[index]+new_col_suffix] = self[object_list_columns[index]].map( lambda  x: hash(x))\n",
    "            self.drop([object_list_columns[index]],inplace=True,axis=1)\n",
    "    return self\n",
    "\n",
    "X_train = convert_obj_to_int(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8999999999999999, bagging_freq=1,\n",
       "               feature_fraction=0.8999999999999999, lambda_l1=10.0,\n",
       "               lambda_l2=1e-08, learning_rate=0.29287582078739416,\n",
       "               loss_function='Logloss', max_bin=255, max_depth=10,\n",
       "               metric='binary_logloss', min_data_in_leaf=20,\n",
       "               min_split_gain=0.001, min_sum_hessian_in_leaf=0,\n",
       "               n_estimators=625, num_leaves=80, objective='binary')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb48128 = lgb.LGBMClassifier(**best_p_l_48128, loss_function='Logloss')\n",
    "lgb48128.fit(X_train, y_train, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sj_test.drop([\"click\"],axis=1)\n",
    "X_test = convert_obj_to_int(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb48128_pred = pd.DataFrame(lgb48128.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb48128_pred.to_csv(\"lgb48128_pred.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
